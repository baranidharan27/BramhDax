{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3322.20s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docling in ./env1/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: beautifulsoup4<4.13.0,>=4.12.3 in ./env1/lib/python3.10/site-packages (from docling) (4.12.3)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in ./env1/lib/python3.10/site-packages (from docling) (2025.1.31)\n",
      "Requirement already satisfied: deepsearch-glm<2.0.0,>=1.0.0 in ./env1/lib/python3.10/site-packages (from docling) (1.0.0)\n",
      "Requirement already satisfied: docling-core<3.0.0,>=2.18.0 in ./env1/lib/python3.10/site-packages (from docling-core[chunking]<3.0.0,>=2.18.0->docling) (2.18.1)\n",
      "Requirement already satisfied: docling-ibm-models<4.0.0,>=3.3.0 in ./env1/lib/python3.10/site-packages (from docling) (3.3.2)\n",
      "Requirement already satisfied: docling-parse<4.0.0,>=3.3.0 in ./env1/lib/python3.10/site-packages (from docling) (3.3.1)\n",
      "Requirement already satisfied: easyocr<2.0,>=1.7 in ./env1/lib/python3.10/site-packages (from docling) (1.7.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./env1/lib/python3.10/site-packages (from docling) (1.2.0)\n",
      "Requirement already satisfied: huggingface_hub<1,>=0.23 in ./env1/lib/python3.10/site-packages (from docling) (0.28.1)\n",
      "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in ./env1/lib/python3.10/site-packages (from docling) (5.3.1)\n",
      "Requirement already satisfied: marko<3.0.0,>=2.1.2 in ./env1/lib/python3.10/site-packages (from docling) (2.1.2)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in ./env1/lib/python3.10/site-packages (from docling) (3.1.5)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in ./env1/lib/python3.10/site-packages (from docling) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in ./env1/lib/python3.10/site-packages (from docling) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./env1/lib/python3.10/site-packages (from docling) (2.10.6)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in ./env1/lib/python3.10/site-packages (from docling) (2.7.1)\n",
      "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in ./env1/lib/python3.10/site-packages (from docling) (4.30.1)\n",
      "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in ./env1/lib/python3.10/site-packages (from docling) (1.1.2)\n",
      "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in ./env1/lib/python3.10/site-packages (from docling) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.2 in ./env1/lib/python3.10/site-packages (from docling) (2.32.3)\n",
      "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in ./env1/lib/python3.10/site-packages (from docling) (1.3.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in ./env1/lib/python3.10/site-packages (from docling) (1.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in ./env1/lib/python3.10/site-packages (from docling) (4.67.1)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.5 in ./env1/lib/python3.10/site-packages (from docling) (0.12.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./env1/lib/python3.10/site-packages (from beautifulsoup4<4.13.0,>=4.12.3->docling) (2.6)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (1.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (4.23.0)\n",
      "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (3.77.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (6.0.2)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in ./env1/lib/python3.10/site-packages (from docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (4.12.2)\n",
      "Requirement already satisfied: semchunk<3.0.0,>=2.2.0 in ./env1/lib/python3.10/site-packages (from docling-core[chunking]<3.0.0,>=2.18.0->docling) (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./env1/lib/python3.10/site-packages (from docling-core[chunking]<3.0.0,>=2.18.0->docling) (4.48.3)\n",
      "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in ./env1/lib/python3.10/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (3.1.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in ./env1/lib/python3.10/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in ./env1/lib/python3.10/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (4.11.0.86)\n",
      "Requirement already satisfied: safetensors<1,>=0.4.3 in ./env1/lib/python3.10/site-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.3.0->docling) (0.5.2)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in ./env1/lib/python3.10/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (2.5.1)\n",
      "Requirement already satisfied: torchvision<1,>=0 in ./env1/lib/python3.10/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (0.20.1)\n",
      "Requirement already satisfied: scikit-image in ./env1/lib/python3.10/site-packages (from easyocr<2.0,>=1.7->docling) (0.25.1)\n",
      "Requirement already satisfied: python-bidi in ./env1/lib/python3.10/site-packages (from easyocr<2.0,>=1.7->docling) (0.6.3)\n",
      "Requirement already satisfied: Shapely in ./env1/lib/python3.10/site-packages (from easyocr<2.0,>=1.7->docling) (2.0.7)\n",
      "Requirement already satisfied: pyclipper in ./env1/lib/python3.10/site-packages (from easyocr<2.0,>=1.7->docling) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in ./env1/lib/python3.10/site-packages (from easyocr<2.0,>=1.7->docling) (1.11.1.3)\n",
      "Requirement already satisfied: filelock in ./env1/lib/python3.10/site-packages (from huggingface_hub<1,>=0.23->docling) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env1/lib/python3.10/site-packages (from huggingface_hub<1,>=0.23->docling) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./env1/lib/python3.10/site-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n",
      "Requirement already satisfied: et-xmlfile in ./env1/lib/python3.10/site-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env1/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env1/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env1/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./env1/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./env1/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./env1/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.3.0->docling) (1.0.1)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in ./env1/lib/python3.10/site-packages (from python-pptx<2.0.0,>=1.0.2->docling) (3.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env1/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env1/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env1/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.2->docling) (2.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./env1/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->docling) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./env1/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->docling) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./env1/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->docling) (13.9.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./env1/lib/python3.10/site-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4.0.0,>=3.3.0->docling) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./env1/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./env1/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./env1/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.18.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in ./env1/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./env1/lib/python3.10/site-packages (from rich>=10.11.0->typer<0.13.0,>=0.12.5->docling) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./env1/lib/python3.10/site-packages (from rich>=10.11.0->typer<0.13.0,>=0.12.5->docling) (2.19.1)\n",
      "Requirement already satisfied: mpire[dill] in ./env1/lib/python3.10/site-packages (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (2.10.2)\n",
      "Requirement already satisfied: networkx in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env1/lib/python3.10/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env1/lib/python3.10/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env1/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env1/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.21.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in ./env1/lib/python3.10/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./env1/lib/python3.10/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.1.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./env1/lib/python3.10/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./env1/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.13.0,>=0.12.5->docling) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env1/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.0.2)\n",
      "Requirement already satisfied: multiprocess in ./env1/lib/python3.10/site-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.70.17)\n",
      "Requirement already satisfied: dill>=0.3.9 in ./env1/lib/python3.10/site-packages (from multiprocess->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.18.0->docling) (0.3.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3328.61s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./env1/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in ./env1/lib/python3.10/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in ./env1/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in ./env1/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./env1/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./env1/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./env1/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./env1/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env1/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env1/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env1/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env1/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env1/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env1/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env1/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env1/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env1/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env1/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in ./env1/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./env1/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env1/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3334.91s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vllm==0.6.6 in ./env1/lib/python3.10/site-packages (0.6.6)\n",
      "Requirement already satisfied: psutil in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (7.0.0)\n",
      "Requirement already satisfied: sentencepiece in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (4.67.1)\n",
      "Requirement already satisfied: blake3 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.45.2 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (4.48.3)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.21.0)\n",
      "Requirement already satisfied: protobuf in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (5.29.3)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.115.8)\n",
      "Requirement already satisfied: aiohttp in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (3.11.12)\n",
      "Requirement already satisfied: openai>=1.52.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (1.63.0)\n",
      "Requirement already satisfied: uvicorn[standard] in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (2.10.6)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.21.1)\n",
      "Requirement already satisfied: pillow in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (10.4.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (7.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.8.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.10.9)\n",
      "Requirement already satisfied: outlines==0.1.11 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (1.2.2)\n",
      "Requirement already satisfied: xgrammar>=0.1.6 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.1.11)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (3.17.0)\n",
      "Requirement already satisfied: partial-json-parser in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (26.2.1)\n",
      "Requirement already satisfied: msgspec in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (8.6.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.0 in ./env1/lib/python3.10/site-packages (from mistral_common[opencv]>=1.5.0->vllm==0.6.6) (1.5.3)\n",
      "Requirement already satisfied: pyyaml in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (6.0.2)\n",
      "Requirement already satisfied: einops in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.8.1 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.8.1)\n",
      "Requirement already satisfied: depyf==0.18.0 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (3.1.1)\n",
      "Requirement already satisfied: ray>=2.9 in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (2.42.1)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (12.570.86)\n",
      "Requirement already satisfied: torch==2.5.1 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in ./env1/lib/python3.10/site-packages (from vllm==0.6.6) (0.0.28.post3)\n",
      "Requirement already satisfied: astor in ./env1/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.6.6) (0.8.1)\n",
      "Requirement already satisfied: dill in ./env1/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.6.6) (0.3.9)\n",
      "Requirement already satisfied: interegular in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (3.1.5)\n",
      "Requirement already satisfied: nest_asyncio in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (1.6.0)\n",
      "Requirement already satisfied: diskcache in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (5.6.3)\n",
      "Requirement already satisfied: referencing in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (4.23.0)\n",
      "Requirement already satisfied: pycountry in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (20241001)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in ./env1/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.6.6) (0.1.26)\n",
      "Requirement already satisfied: networkx in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (3.4.2)\n",
      "Requirement already satisfied: fsspec in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env1/lib/python3.10/site-packages (from torch==2.5.1->vllm==0.6.6) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env1/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.1->vllm==0.6.6) (1.3.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in ./env1/lib/python3.10/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm==0.6.6) (0.45.3)\n",
      "Requirement already satisfied: packaging in ./env1/lib/python3.10/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm==0.6.6) (24.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in ./env1/lib/python3.10/site-packages (from mistral_common[opencv]>=1.5.0->vllm==0.6.6) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./env1/lib/python3.10/site-packages (from openai>=1.52.0->vllm==0.6.6) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./env1/lib/python3.10/site-packages (from openai>=1.52.0->vllm==0.6.6) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./env1/lib/python3.10/site-packages (from openai>=1.52.0->vllm==0.6.6) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./env1/lib/python3.10/site-packages (from openai>=1.52.0->vllm==0.6.6) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./env1/lib/python3.10/site-packages (from openai>=1.52.0->vllm==0.6.6) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./env1/lib/python3.10/site-packages (from pydantic>=2.9->vllm==0.6.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./env1/lib/python3.10/site-packages (from pydantic>=2.9->vllm==0.6.6) (2.27.2)\n",
      "Requirement already satisfied: click>=7.0 in ./env1/lib/python3.10/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.6.6) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./env1/lib/python3.10/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.6.6) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in ./env1/lib/python3.10/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.6.6) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in ./env1/lib/python3.10/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.6.6) (1.5.0)\n",
      "Requirement already satisfied: aiohttp-cors in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (0.7.0)\n",
      "Requirement already satisfied: colorful in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (0.5.6)\n",
      "Requirement already satisfied: opencensus in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (0.11.4)\n",
      "Requirement already satisfied: smart-open in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (7.1.0)\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (20.29.2)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in ./env1/lib/python3.10/site-packages (from ray[default]>=2.9->vllm==0.6.6) (1.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (2.4.6)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (25.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env1/lib/python3.10/site-packages (from aiohttp->vllm==0.6.6) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env1/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.6.6) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env1/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.6.6) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env1/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.6.6) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env1/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.6.6) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./env1/lib/python3.10/site-packages (from tiktoken>=0.6.0->vllm==0.6.6) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./env1/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm==0.6.6) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./env1/lib/python3.10/site-packages (from transformers>=4.45.2->vllm==0.6.6) (0.5.2)\n",
      "Requirement already satisfied: pybind11 in ./env1/lib/python3.10/site-packages (from xgrammar>=0.1.6->vllm==0.6.6) (2.13.6)\n",
      "Requirement already satisfied: pytest in ./env1/lib/python3.10/site-packages (from xgrammar>=0.1.6->vllm==0.6.6) (8.3.4)\n",
      "Requirement already satisfied: zipp>=3.20 in ./env1/lib/python3.10/site-packages (from importlib_metadata->vllm==0.6.6) (3.21.0)\n",
      "Requirement already satisfied: h11>=0.8 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in ./env1/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.6.6) (14.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./env1/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm==0.6.6) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./env1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm==0.6.6) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./env1/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.6.6) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./env1/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.6.6) (0.22.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in ./env1/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm==0.6.6) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in ./env1/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm==0.6.6) (4.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env1/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm==0.6.6) (3.0.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in ./env1/lib/python3.10/site-packages (from opencensus->ray[default]>=2.9->vllm==0.6.6) (0.1.3)\n",
      "Requirement already satisfied: six~=1.16 in ./env1/lib/python3.10/site-packages (from opencensus->ray[default]>=2.9->vllm==0.6.6) (1.17.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in ./env1/lib/python3.10/site-packages (from opencensus->ray[default]>=2.9->vllm==0.6.6) (2.24.1)\n",
      "Requirement already satisfied: iniconfig in ./env1/lib/python3.10/site-packages (from pytest->xgrammar>=0.1.6->vllm==0.6.6) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./env1/lib/python3.10/site-packages (from pytest->xgrammar>=0.1.6->vllm==0.6.6) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in ./env1/lib/python3.10/site-packages (from pytest->xgrammar>=0.1.6->vllm==0.6.6) (2.2.1)\n",
      "Requirement already satisfied: wrapt in ./env1/lib/python3.10/site-packages (from smart-open->ray[default]>=2.9->vllm==0.6.6) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./env1/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (1.67.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./env1/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (1.26.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in ./env1/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (2.38.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./env1/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env1/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./env1/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./env1/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.6.6) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vllm==0.6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling.loader import ExportType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_env_from_colab_or_os(key):\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        try:\n",
    "            return userdata.get(key)\n",
    "        except userdata.SecretNotFoundError:\n",
    "            pass\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return os.getenv(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
    "FILE_PATH = [\"paper.pdf\"]  # Docling Technical Report\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GEN_MODEL_ID = \"ibm-granite/granite-vision-3.1-2b-preview\"\n",
    "#GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "QUESTION = \"explain me what error used in the uploaded document?\"\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
    ")\n",
    "TOP_K = 3\n",
    "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Initialize the HuggingFaceEndpoint with the Granite model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"ibm-granite/granite-vision-3.1-2b-preview\",  # Make sure the model repo is correct\n",
    "    huggingfacehub_api_token=HF_TOKEN,  # The Hugging Face token\n",
    "    task=\"text-generation\",  # Ensure this task is appropriate for the Granite model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "from docling.chunking import HybridChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    splits = docs\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ],\n",
    "    )\n",
    "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='FastVPINNs: Tensor-Driven Acceleration of VPINNs for Complex Geometries\\nThivin Anandh 1\\nthivinanandh@iisc.ac.in\\nDivij Ghose 1\\ndivijghose@iisc.ac.in\\nHimanshu Jain 2\\nms19026@iisermohali.ac.in\\nSashikumaar Ganesan 1 ∗\\nsashi@iisc.ac.in\\n1 Department of Computational and Data Sciences\\nIndian Institute of Science, Bangalore\\nKarnataka, India\\n2 Department of Physical Sciences\\nIndian Institute of Science Education and Research, Mohali\\nPunjab, India\\n∗ Corresponding author'\n",
      "- d.page_content=\"Abstract\\nVariational Physics-Informed Neural Networks (VPINNs) utilize a variational loss function to solve partial differential equations, mirroring Finite Element Analysis techniques. Traditional hp-VPINNs, while effective for high-frequency problems, are computationally intensive and scale poorly with increasing element counts, limiting their use in complex geometries. This work introduces FastVPINNs, a tensor-based advancement that significantly reduces computational overhead and improves scalability. Using optimized tensor operations, FastVPINNs achieve a 100-fold reduction in the median training time per epoch compared to traditional hp-VPINNs. With proper choice of hyperparameters, FastVPINNs surpass conventional PINNs in both speed and accuracy, especially in problems with highfrequency solutions. Demonstrated effectiveness in solving inverse problems on complex domains underscores FastVPINNs' potential for widespread application in scientific and engineering challenges, opening new avenues for practical implementations in scientific machine learning.\\nKeywords: Physics-informed neural networks, Variational physics-informed neural networks, Domain decomposition, hp-Variational physics-informed neural networks\"\n",
      "- d.page_content='1 Introduction\\nAt present, the realm of applied mathematics is witnessing substantial progress as a result of incorporating deep learning approaches in solving partial differential equations (PDEs). These methods, collectively termed scientific machine learning (SciML) (Cuomo et al. (2022); Baker et al. (2019); Psaros et al. (2023)), often complement or replace traditional solvers. Despite the dominance of conventional numerical methods such as the finite element method (FEM), which boasts several open-source solvers (Wilbrandt et al. (2017); Bangerth et al. (2007); Ganesan and Shah (2020)), SciML has rapidly evolved. This evolution has led to a growing repertoire of accessible SciML libraries (Lu et al. (2021a); NVIDIA Modulus).\\nSince the advent of physics-informed neural networks (PINNs) (Lagaris et al. (1998); Raissi et al. (2019)), the application of such methods has surged. PINNs enhance the\\ntypical data-driven loss function of neural networks by incorporating an additional term that minimizes the residual of the underlying PDE and enforces physics-based constraints. Features such as the ease of obtaining gradients through automatic differentiation, and the ability to train networks for both forward and inverse modeling, make PINNs superior to traditional methods (Abueidda et al. (2021); Lu et al. (2021b)). Consequently, PINNs have found widespread application in various fields, including solid mechanics (Haghighat et al. (2021); Zhang et al. (2022)), fluid mechanics (Mao et al. (2020); Cai et al. (2021); Eivazi et al. (2022)), and geophysics (Smith et al. (2021)).\\nAn extension of PINNs, Variational PINNs (VPINNs), utilize the weak form of the PDE in their loss functions, mirroring the Petrov-Galerkin framework used in conventional FEM (Kharazmi et al. (2019); Khodayi-Mehr and Zavlanos (2020)). Despite their computational demand due to the necessity to numerically compute integrals in the loss function, VPINNs represent a significant step forward in applying neural networks to PDEs.'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3357.42s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: grpcio\n",
      "Version: 1.67.1\n",
      "Summary: HTTP/2-based RPC framework\n",
      "Home-page: https://grpc.io\n",
      "Author: The gRPC Authors\n",
      "Author-email: grpc-io@googlegroups.com\n",
      "License: Apache License 2.0\n",
      "Location: /home/parani/IBM/env1/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: grpcio-tools, pymilvus\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show grpcio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "/home/parani/IBM/env1/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Embed documents using HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
    "\n",
    "# Assuming 'splits' are your document splits (from Docling)\n",
    "# Create a FAISS vector store from the documents\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
    "\n",
    "# Now you can use the vectorstore with a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "\n",
    "# Define the question answering chain\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=GEN_MODEL_ID,\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Invoke the RAG chain\n",
    "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "# from tempfile import mkdtemp\n",
    "# from langchain_milvus import Milvus\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
    "\n",
    "\n",
    "# milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
    "# vectorstore = Milvus.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embedding,\n",
    "#     collection_name=\"docling_demo\",\n",
    "#     connection_args={\"uri\": milvus_uri},\n",
    "#     index_params={\"index_type\": \"FLAT\"},\n",
    "#     drop_old=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=GEN_MODEL_ID,\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    task = \"text-generation\",\n",
    ")\n",
    "\n",
    "\n",
    "def clip_text(text, threshold=100):\n",
    "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parani/IBM/env1/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "explain me what error used in the uploaded document?\n",
      "\n",
      "Answer:\n",
      "In the uploaded document, the authors introduce and use several types of errors or loss functions to train their Physics-Informed Neural Networks (PINNs) and hp-VPINNs for solving forward and inverse ...\n",
      "\n",
      "Source 1:\n",
      "  text: \"2.1 Governing Equations\\nConsider a two-dimensional steady-state convection-diffusion equation:\\n\\nHere, x \\u2208 \\u2126, \\u03b5 , and b are the diffusion coefficient and convective velocity, respectively. In addition, f ( x ) is a known source function with appropriate smoothness. The Dirichlet boundary condition u x ( ) = g x ( ) is imposed on the domain boundary ...\"\n",
      "  source: paper.pdf\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/33', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 90.0, 't': 203.5019989013672, 'r': 427.9049987792969, 'b': 193.96800231933594, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 70]}]}, {'self_ref': '#/texts/34', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 2, 'bbox': {'l': 200.26600646972656, 't': 181.0749969482422, 'r': 522.0009765625, 'b': 152.50599670410156, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 86]}]}, {'self_ref': '#/texts/35', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 90.0, 't': 137.27000427246094, 'r': 522.0029907226562, 'b': 87.0459976196289, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 367]}]}, {'self_ref': '#/texts/37', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 90.0, 't': 697.6300048828125, 'r': 118.12000274658203, 'b': 688.0960083007812, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 6]}]}, {'self_ref': '#/texts/38', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 3, 'bbox': {'l': 231.92799377441406, 't': 680.8480224609375, 'r': 522.0009765625, 'b': 652.2789916992188, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 68]}]}, {'self_ref': '#/texts/39', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 90.0, 't': 639.927978515625, 'r': 501.822998046875, 'b': 630.3939819335938, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 89]}]}], 'headings': ['2.1 Governing Equations'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n",
      "\n",
      "Source 2:\n",
      "  text: \"2.3 hp-Variational Physics Informed Neural Network\\nIn this section, we initially establish the variational form of the Poisson equation (2), followed by introducing the Variational Physics Informed Neural Network. Let H (\\u2126) denote 1 the conventional Sobolev space, and define\\n\\nThe subsequent procedure consists of taking the equation (2), multiplying...\"\n",
      "  source: paper.pdf\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/54', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 678.3209838867188, 'r': 522.0009765625, 'b': 641.6890258789062, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 224]}]}, {'self_ref': '#/texts/55', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 218.69500732421875, 't': 630.3809814453125, 'r': 393.30499267578125, 'b': 618.3499755859375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 37]}]}, {'self_ref': '#/texts/56', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 604.5449829101562, 'r': 522.0029907226562, 'b': 554.3629760742188, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 346]}]}, {'self_ref': '#/texts/57', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 536.7990112304688, 'r': 195.54299926757812, 'b': 527.2650146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 21]}]}, {'self_ref': '#/texts/58', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 236.99099731445312, 't': 523.25, 'r': 375.0140075683594, 'b': 513.7160034179688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 35]}]}, {'self_ref': '#/texts/59', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 193.197998046875, 't': 495.7980041503906, 'r': 522.0009765625, 'b': 469.0989990234375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 57]}]}, {'self_ref': '#/texts/60', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 463.6090087890625, 'r': 522.0029907226562, 'b': 386.3290100097656, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 529]}]}, {'self_ref': '#/texts/61', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 368.7650146484375, 'r': 203.88499450683594, 'b': 358.0140075683594, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 25]}]}, {'self_ref': '#/texts/62', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 227.125, 't': 355.2149963378906, 'r': 522.0, 'b': 344.4649963378906, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 49]}]}, {'self_ref': '#/texts/63', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 335.7749938964844, 'r': 117.90899658203125, 'b': 326.2409973144531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 5]}]}, {'self_ref': '#/texts/64', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 148.18899536132812, 't': 326.2359924316406, 'r': 463.8089904785156, 'b': 292.8550109863281, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 94]}]}, {'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 286.27398681640625, 'r': 474.2149963378906, 'b': 276.739990234375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 78]}]}, {'self_ref': '#/texts/66', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 192.60299682617188, 't': 264.8240051269531, 'r': 419.39801025390625, 'b': 191.05999755859375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 124]}]}, {'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 179.02999877929688, 'r': 366.6440124511719, 'b': 169.15699768066406, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 58]}]}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 90.0, 't': 165.4810028076172, 'r': 522.0029907226562, 'b': 115.30000305175781, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 276]}]}, {'self_ref': '#/texts/69', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 4, 'bbox': {'l': 289.5679931640625, 't': 112.35099792480469, 'r': 289.5679931640625, 'b': 102.9729995727539, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/70', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 4, 'bbox': {'l': 242.35699462890625, 't': 116.38600158691406, 'r': 522.0009765625, 'b': 86.55799865722656, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/73', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 90.0, 't': 699.5819702148438, 'r': 522.0059814453125, 'b': 632.77197265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 430]}]}, {'self_ref': '#/texts/74', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 5, 'bbox': {'l': 178.87899780273438, 't': 622.0540161132812, 'r': 522.0009765625, 'b': 594.3300170898438, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 69]}]}, {'self_ref': '#/texts/75', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 90.0, 't': 583.708984375, 'r': 269.4590148925781, 'b': 574.1749877929688, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 39]}]}, {'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 5, 'bbox': {'l': 214.15699768066406, 't': 561.4080200195312, 'r': 522.0, 'b': 528.0260009765625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 62]}]}], 'headings': ['2.3 hp-Variational Physics Informed Neural Network'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n",
      "\n",
      "Source 3:\n",
      "  text: \"4.7 Investigating Inverse Problems with FastVPINNs\\nIn PINNs, inverse problems involve the use of neural networks to infer unidentified PDE parameters, aided by observed solutions at scattered data points, usually in complex physical systems. By enhancing the loss function with data from sensor points scattered across the 2D domain, the network is c...\"\n",
      "  source: paper.pdf\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/206', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 90.0, 't': 370.65301513671875, 'r': 522.0050048828125, 'b': 293.37298583984375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 481]}]}, {'self_ref': '#/texts/207', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'formula', 'prov': [{'page_no': 19, 'bbox': {'l': 228.0050048828125, 't': 283.6289978027344, 'r': 383.9960021972656, 'b': 272.87799072265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 37]}]}, {'self_ref': '#/texts/208', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 19, 'bbox': {'l': 90.0, 't': 264.3500061035156, 'r': 522.0059814453125, 'b': 159.9720001220703, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 688]}]}], 'headings': ['4.7 Investigating Inverse Problems with FastVPINNs'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
    "\n",
    "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
    "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
    "for i, doc in enumerate(resp_dict[\"context\"]):\n",
    "    print()\n",
    "    print(f\"Source {i+1}:\")\n",
    "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
    "    for key in doc.metadata:\n",
    "        if key != \"pk\":\n",
    "            val = doc.metadata.get(key)\n",
    "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
    "            print(f\"  {key}: {clipped_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain_docling.loader import DoclingLoader, ExportType\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "FILE_PATH = [\"paper.pdf\"]  # replace with your file path\n",
    "\n",
    "# Set export type as necessary, usually ExportType.DOC_CHUNKS for document parsing\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=None,  # Add chunker if you need specific text handling\n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content: FastVPINNs: Tensor-Driven Acceleration of VPINNs for Complex Geometries\n",
      "Thivin Anandh 1\n",
      "thivinanandh@iisc.ac.in\n",
      "Divij Ghose 1\n",
      "divijghose@iisc.ac.in\n",
      "Himanshu Jain 2\n",
      "ms19026@iisermohali.ac.in\n",
      "Sashikumaar Ganesan 1 ∗\n",
      "sashi@iisc.ac.in\n",
      "1 Department of Computational and Data Sciences\n",
      "Indian Institute of Science, Bangalore\n",
      "Karnataka, India\n",
      "2 Department of Physical Sciences\n",
      "Indian Institute of Science Education and Research, Mohali\n",
      "Punjab, India\n",
      "∗ Corresponding author\n",
      "Page content: Abstract\n",
      "Variational Physics-Informed Neural Networks (VPINNs) utilize a variational loss function to solve partial differential equations, mirroring Finite Element Analysis techniques. Traditional hp-VPINNs, while effective for high-frequency problems, are computationally intensive and scale poorly with increasing element counts, limiting their use in complex geometries. This work introduces FastVPINNs, a tensor-based advancement that significantly reduces computational overhead and improves scalability. Using optimized tensor operations, FastVPINNs achieve a 100-fold reduction in the median training time per epoch compared to traditional hp-VPINNs. With proper choice of hyperparameters, FastVPINNs surpass conventional PINNs in both speed and accuracy, especially in problems with highfrequency solutions. Demonstrated effectiveness in solving inverse problems on complex domains underscores FastVPINNs' potential for widespread application in scientific and engineering challenges, opening new avenues for practical implementations in scientific machine learning.\n",
      "Keywords: Physics-informed neural networks, Variational physics-informed neural networks, Domain decomposition, hp-Variational physics-informed neural networks\n",
      "Page content: 1 Introduction\n",
      "At present, the realm of applied mathematics is witnessing substantial progress as a result of incorporating deep learning approaches in solving partial differential equations (PDEs). These methods, collectively termed scientific machine learning (SciML) (Cuomo et al. (2022); Baker et al. (2019); Psaros et al. (2023)), often complement or replace traditional solvers. Despite the dominance of conventional numerical methods such as the finite element method (FEM), which boasts several open-source solvers (Wilbrandt et al. (2017); Bangerth et al. (2007); Ganesan and Shah (2020)), SciML has rapidly evolved. This evolution has led to a growing repertoire of accessible SciML libraries (Lu et al. (2021a); NVIDIA Modulus).\n",
      "Since the advent of physics-informed neural networks (PINNs) (Lagaris et al. (1998); Raissi et al. (2019)), the application of such methods has surged. PINNs enhance the\n",
      "typical data-driven loss function of neural networks by incorporating an additional term that minimizes the residual of the underlying PDE and enforces physics-based constraints. Features such as the ease of obtaining gradients through automatic differentiation, and the ability to train networks for both forward and inverse modeling, make PINNs superior to traditional methods (Abueidda et al. (2021); Lu et al. (2021b)). Consequently, PINNs have found widespread application in various fields, including solid mechanics (Haghighat et al. (2021); Zhang et al. (2022)), fluid mechanics (Mao et al. (2020); Cai et al. (2021); Eivazi et al. (2022)), and geophysics (Smith et al. (2021)).\n",
      "An extension of PINNs, Variational PINNs (VPINNs), utilize the weak form of the PDE in their loss functions, mirroring the Petrov-Galerkin framework used in conventional FEM (Kharazmi et al. (2019); Khodayi-Mehr and Zavlanos (2020)). Despite their computational demand due to the necessity to numerically compute integrals in the loss function, VPINNs represent a significant step forward in applying neural networks to PDEs.\n",
      "Page content: 1 Introduction\n",
      "Based on VPINN, hp-VPINNs have been developed to improve accuracy through domain decomposition (h-refinement) or increasing polynomial order (p-refinement) (Kharazmi et al. (2021)). Although hp-VPINNs offer superior accuracy in various problems, they suffer from critical limitations that hinder their practical application. These limitations include their computational complexity, linear scaling of training time with element count, and difficulty in handling complex geometries with skewed elements. These issues are evidenced in both academic and practical scenarios and have been a barrier to greater adoption despite various attempts to deploy hp-VPINNs in different applications (Radin et al. (2023); Yang and Foster (2021)).\n",
      "Furthermore, recent developments such as convolutional PINNs (cv-PINNs) (Liu and Wu (2023)) introduced convolutional operations to accelerate the training of hp-VPINNs. Despite claims of superior performance, cv-PINNs still exhibited linear increases in training time with element count in 1D studies, and their solutions have been limited to domains suitable for decomposition into regular quadrilateral cells.\n",
      "In response to these challenges, this work introduces FastVPINNs, a novel framework designed to address the limitations of hp-VPINNs. The proposed FastVPINNs leverage tensor-based operations to compute the loss, substantially reducing training times and diminishing the impact of increasing element counts. This advancement enables the handling of complex geometries, significantly broadening the practical applicability of our approach.\n",
      "Page content: 2.1 Governing Equations\n",
      "Consider a two-dimensional steady-state convection-diffusion equation:\n",
      "\n",
      "Here, x ∈ Ω, ε , and b are the diffusion coefficient and convective velocity, respectively. In addition, f ( x ) is a known source function with appropriate smoothness. The Dirichlet boundary condition u x ( ) = g x ( ) is imposed on the domain boundary ∂ Ω. The two-dimensional steady-state Poisson equation can be obtained from (1) by substituting b = (0 0) , T and\n",
      "ε = 1.\n",
      "\n",
      "For the remainder of our discussion in this section, we will be using (2) as a reference.\n",
      "Page content: 2.2 Physics Informed Neural Networks\n",
      "The result generated by a deep neural network is typically structured as a parametric function of the variable x , denoted as u NN ( x W,b ; ). In this context, W and b represent the weights and biases of the network. When the neural network consists of h hidden layers, with the i th layer containing n i neurons, the mathematical representation of the function takes the following shape:\n",
      "\n",
      "Here, l : R n h → R is a linear mapping in the output layer and T ( ) i ( ) = · σ W ( ( ) i ×· + b ( ) i ) is a non-linear mapping in the i th layer ( i = 1 2 , , · · · , h ), with the non-linear activation function σ and the weights W ( ) i and biases b ( ) i of the respective layers.\n",
      "The neural network's output u NN ( x W,b ; ) can serve as an approximation to the unknown solution u x ( ) of the equation 2 by training the deep neural network. Physics-Informed Neural Networks aim to achieve this estimation by systematically reducing the residual arising from the governing equations specified in equation 2 with u NN ( x W,b ; ). Specifically, we refer to the residual related to the partial differential equation (PDE) and the boundary conditions as P and B , respectively, that is,\n",
      "\n",
      "The loss function employed in the neural network architecture is designed to integrate two primary components: a Partial Differential Equation (PDE) loss and a boundary loss. These components are defined at particular training points within the domain to reduce inaccuracies associated with the PDE and boundary constraints. This division of the loss function allows for a focused reduction in the difference between the neural network's forecasts and the expected physical phenomena described by the governing equations and boundary constraints. In particular, we define\n",
      "\n",
      "where N T is the total number of training points in the interior of the domain Ω, N D is the total number of training points on the boundary ∂ Ω and τ is a scaling factor applied to control the penalty on the boundary term.\n",
      "where\n",
      "Page content: 2.3 hp-Variational Physics Informed Neural Network\n",
      "In this section, we initially establish the variational form of the Poisson equation (2), followed by introducing the Variational Physics Informed Neural Network. Let H (Ω) denote 1 the conventional Sobolev space, and define\n",
      "\n",
      "The subsequent procedure consists of taking the equation (2), multiplying it by v ∈ V , integrating over Ω, and then utilizing integration by parts on the second derivative term. For more detailed information, please refer to (Ganesan and Tobiska (2017)). Consequently, the variational representation of the Poisson equation can be formulated as:\n",
      "Find u ∈ V such that,\n",
      "\n",
      "\n",
      "The domain Ω is then divided into an array of non-overlapping cells, labeled as K k , where k = 1 2 , , . . . , N elem , ensuring that the complete union ⋃ N elem k =1 K k = Ω covers the entire domain Ω. In this context, we define V h as a finite-dimensional subspace of V , spanned by the basis functions ϕ h := { ϕ j ( x ) } , j = 1 2 , , . . . , N test , where N test indicates the total number of basis functions in V h . As a result, the discretized variational formulation related to equation (6) can be written as follows,\n",
      "Find u h ∈ V h such that,\n",
      "\n",
      "where\n",
      "\n",
      "These integrals can be approximated by employing a quadrature rule, leading to\n",
      "\n",
      "Here, N quad is the number of quadrature points in a cell.\n",
      "The hp-Variational Physics Informed Neural Networks (hp-VPINNs) framework, as presented by Kharazmi et al. (2021), utilizes specific test functions v k , where k ranges from 1 to N elem, that are localized and defined within individual non-overlapping cells across the domain.\n",
      "̸\n",
      "\n",
      "Here, v p represents a polynomial function of degree p . This selection of test and solution spaces results in a Petrov-Galerkin finite element method. Specifically, u h is estimated by u NN ( x W,b ; ), which is the neural network solution, whereas the test function v h is a predetermined polynomial function. By utilizing these functions, we establish the cell-wise residual of the variational form (7) with u NN ( x W,b ; ) as\n",
      "\n",
      "Further, define the variational loss by\n",
      "\n",
      "Page content: 2.3 hp-Variational Physics Informed Neural Network\n",
      "and the cost function of the neural network in hp-VPINN as\n",
      "\n",
      "Here, L b is the Dirichlet boundary loss as expressed in (5) and τ is a scaling factor applied to control the penalty on the boundary term.\n",
      "Remark: The only distinction between VPINNs and hp-VPINN resides in the selection of the test function. Within the framework of VPINNs, a polynomial that has global support throughout the domain is employed as a test function. Conversely, in the context of hpVPINN, a compilation of polynomials, each offering support on an element-wise basis, is utilized. Figure 1 represents the schematic of VPINNs for a 2D Poisson problem.\n",
      "Page content: 3 Implementation of hp-VPINNs\n",
      "This section focuses on the existing implementation of hp-VPINNs. Initially, we explain the current approach to calculating the variational loss in hp-VPINNs using numerical integration methods like Gauss-Lobatto or Gauss-Legendre to achieve accurate integral approximations. Next, we will examine two key limitations of the existing implementation. Firstly, we will explore why the current approach leads to longer training times. Secondly, we will discuss why it may not be suitable for problems involving complex shapes.\n",
      "Page content: 3.1 Overview of Current hp-VPINNs Implementation\n",
      "To calculate the cost function related to hp-VPINNs, as specified in Equation 11, it is essential to estimate the integration outlined in Equation 9. This estimation is accomplished by utilizing numerical integration methods, with the Gauss-Lobatto and Gauss-Legendre quadrature methods being particularly effective. As a result of applying these numerical techniques to the integral over the cell K k , W k ( x W,b ; ) becomes\n",
      "\n",
      "Here, N quad denotes the number of quadrature points in a given element K k .\n",
      "Algorithm 1: hp-VPINNs Implementation in Kharazmi et.al\n",
      "Page content: 3.1 Overview of Current hp-VPINNs Implementation\n",
      "# VPINNs Existing Implementation def train_step(): for k in N_elem: u_NN = model(quadrature_points_in_curr_element) # get NN output u_x, u_y = model.get_grad(u_NN) # get sol gradients NN v_kx , v_ky = fem.get_grad(v_k) # get test fn grad j,j_x,j_y = fem.get_jacobians(K_k) # get jacobians w = fem.get_quad_wt(v_k, K_k) # get quad wt r[] = 0 # compute PDE loss for q in N_quad: # number of test functions for j in N_test: # number of quadrature points grad_x = (j[q]/j_x[q])*w[q]*u_x[q]*v_kx[q][j] # du/dx.dv/dx grad_y = (j[q]/j_y[q])*w[q]*u_y[q]*v_ky[q][j] # du/dy.dv/dy r[j] += (grad_x + grad_y -F[q][j]) # Var loss (F is precomputed outside train loop) variational_loss += reduce_mean(square(r)) dirichlet_loss = reduce_mean(square(model(input_bound_pts) -bd_actual) total_loss = variational_loss + tau * dirichlet_loss # Total loss\n",
      "Page content: Nomenclature:\n",
      "v kx, v ky : gradients of the test functions in the x and y directions at the k-th cell. u x, u y : gradients of u NN in the x and y directions (computed using AutoDiff). j[q] : Jacobian of the element at the specified quadrature point. j x[q] , j y[q] : Jacobian of the element at the specified quadrature point in the x and y directions.\n",
      "Algorithm 1 describes the approach for quantifying the loss function in the context of hp-VPINNs, following the guidelines provided in the GitHub repository (Kharazmi (2023)). This approach involves an iterative procedure that covers each element of the computational domain to compute the local PDE loss. Local losses are then combined to obtain the overall PDE loss measure. Central to this method is the need for gradients and function values of the test functions, which are obtained from predefined basis functions such as Jacobi polynomials. Simultaneously, the neural network provides solutions and gradients at specified points within each element. After computing the local losses, the algorithm consolidates these losses from all elements and combines them with the prescribed boundary loss, as detailed in equation (9). This unified loss function is crucial for training the neural network, ensuring that the hp-VPINNs model is finely adjusted not only to the underlying physics described by the PDE but also to the specified boundary constraints.\n",
      "Figure 1: Schematics of Variational PINNs for a 2D Poisson problem.\n",
      "Page content: 3.2 Need for Efficient hp-VPINNs Implementation\n",
      "hp-VPINNs employs h-refinement that restricts the test functions to smaller areas within the computational domain. This restriction of test functions allows hp-VPINNs to capture high frequency features in the solution. However, increasing the number of elements leads to a proportional increase in the time required to train the model.\n",
      "· Training time complexity : The training time of hp-VPINNs increases linearly with the addition of more elements, even when the total number of quadrature points remains constant throughout the domain, as demonstrated in Figure 2. Consequently, employing h-refinement, which involves adding more elements to handle rapidly changing solutions, does not provide the anticipated advantage, as it substantially increases the computational cost.\n",
      "· Handling complex geometries : The current version of hp-VPINNs is limited to operate with structured quadrilateral elements. This limitation stems from the current implementation using constant Jacobian values for each element to transform the gradients from the reference element to the actual element. However, practical applications often require skewed elements within complex domains as shown in Figure 3), where the Jacobian will not be constant within an element.\n",
      "Page content: 4 FastVPINNs Methodology\n",
      "This section introduces FastVPINNs, a novel framework that significantly improves upon the existing hp-VPINNs. FastVPINNs tackles two critical challenges: handling complex geometries and achieving faster training times. We achieve these advancements through several key optimizations, including eliminating element-wise looping, removing redundant computations, and leveraging BLAS (Basic Linear Algebra Subprograms) routines. For\n",
      "Figure 2: hp-VPINNs: Effect of training time on Number of elements (a) Number of residual points vs training time.(Each element has 25 quadrature points, so 30K quadrature points will have 1200 elements).(b) Number of elements vs training time(total number of quadrature points within the domain is kept constant at 6400).\n",
      "Figure 3: Mesh of spur gear with 14,000 quad elements.\n",
      "handling complex geometries, we incorporate concepts of mapped finite elements by utilizing bilinear transformations.\n",
      "Page content: 4.1 Mapped hp-VPINNs\n",
      "Complex geometric shapes frequently lead to the presence of irregular triangles or quadrilaterals in 2D, which pose challenges when it comes to accurately computing integrals and derivatives. To tackle this challenge, the FEM employs mapped finite elements. This approach converts all irregular elements in the actual domain into simpler shapes within a common reference element, as shown in Figure 4.\n",
      "The adoption of mapped finite elements offers several advantages:\n",
      "· The simplification of integrals and derivatives is achieved by moving these calculations to a reference element.\n",
      "· The need to compute gradients multiple times for each element is eliminated, as the reference gradients are consistent across all elements in the domain.\n",
      "In this work, the bilinear transformation is employed when dealing with quadrilateral elements. Further details on bilinear transformation can be found in the Appendix.\n",
      "Figure 4: Bilinear transformation.\n",
      "Page content: 4.2 Optimization I: Enhancing Efficiency with Matrix-Vector Product Reformulation\n",
      "Upon a detailed analysis of Algorithm 1, it is evident that its computational procedure consists mainly of iterative multiplication operations. These operations pertain to the derivatives of test functions and the quadrature weights utilized for numerical integration, which remain constant throughout the training cycle. The only component that undergoes variation at each training step is the predicted solution and its gradients derived from the neural network. Recognizing this recurrent pattern, we've devised an approach to modify the gradient computation, denoted as grad x in Algorithm 1, to be expressed as a matrixvector product. Initially, a matrix is prepared in advance, known as the precomputed test function matrix. This matrix, sized N test × N quad , comprises pre-computed values obtained by multiplying each shape function by the corresponding quadrature weights. During the training process, this matrix is multiplied by the solution of the neural network and a scaling factor known as Jacobian. This multiplication yields a vector of residuals, with dimensions N test × 1. This has the following advantages.\n",
      "· Using BLAS for Faster Calculations: By organizing our loss computations in a matrix-vector format, we can utilize the BLAS (Basic Linear Algebra Subprograms) routines. These optimized routines are designed to operate efficiently on GPUs, enhancing the speed of our calculations.\n",
      "· Elimination of Redundant Calculations: Since the test function matrix is precomputed and remains unchanged during training, except for cases such as moving domain problems where the domain shape changes, it is not necessary to repeatedly compute the product of the derivatives of the shape functions and the quadrature weights at each training iteration. This efficient approach saves considerable time and\n",
      "computational resources, thereby improving the speed and effectiveness of the training process.\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "Despite the efforts made to reduce redundant computations and optimize matrix vector operations, our algorithm still requires the individual processing of each element for the calculation of loss within the computational domain. This means that during every training iteration, the neural network must calculate the solution N elem times (known as forward passes) and then compute the gradients of these solutions another N elem times (known as backward passes) to determine the loss. This sequential process is a major factor that contributes to the slowdown in the training of hp-VPINNs. For basic non-distorted quadrilateral elements (similar to those shown in Figure 5), the Jacobian values are constant for a given element. Instead of computing the gradients individually for each element, a single reference gradient matrix can be computed and later multiplied with the corresponding Jacobians to obtain the actual gradients for each element.\n",
      "In our approach, we exploit these characteristics of a domain composed of regular elements to perform loss computation without the need to iterate through individual elements. The process involves gathering quadrature points, which are used for numerical integration, from all elements across the domain. These points are organized into a single input of dimensions ( N quad x N elem , 2) and then supplied as input to the neural network.Consequently, the neural network produces an output in the form of a vector that can be reorganized into a matrix of size N quad × N elem . Each column of this matrix represents the predicted results at the quadrature points for each element. Subsequently, we proceed by taking each column of this matrix and multiplying it by the corresponding Jacobian. The loss calculation now involves multiplying the premultiplier matrix (reference gradient) with the gradient matrix from the neural network, which is scaled by the Jacobian. The result of this multiplication produces a final matrix with dimensions N test × N elem , where each column represents the residuals computed for each element within the actual domain.\n",
      "The key advantages of this optimized approach include:\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "· Single Backpropagation per Iteration: Through the aggregation of inputs from all elements, we are able to compute the gradients for all elements simultaneously, requiring only a single forward pass and one backward pass (for gradient calculation) across the neural network.\n",
      "· Elimination of Element Looping: By combining all inputs and using matrix multiplication, we avoid individually processing each element. This approach significantly accelerates our computations and enhances the overall computational efficiency.\n",
      "Algorithm 2: Vectorised hp-VPINNs with elimination of element looping\n",
      "# J_x, J_y: premultiplier jacobian matrices (N_quad , N_elem) # F : preassembled force function matrix (N_elem , N_test) # V : test function matrix (N_test , N_quad) # V_x, V_y: test function gradient matrices (N_test , N_quad)\n",
      "Figure 5: Quadrilateral meshes with elements having constant Jacobian.\n",
      "# NOTE : refer Appendix for pseudocode of pre-assembly matrices. def train_step(): u_NN = model(quadrature_points_in_curr_element) # get NN output # get gradients and reshape them u_x, u_y = model.get_gradients().reshape(N_quad , N_elem) # Multiply jacobians of corresponding elements to sol gradients # Perform mat-mat multiplication grad_x = matmul(grad_x_mat , u_x * J_x) # int(du/dx.dv/dx), grad_y = matmul(grad_y_mat , u_y * J_y) # int(du/dy.dv/dy) # obtain mse for each element by row reduction (axis 0) residual_elements = reduce_mean(square(grad_x + grad_y -F), axis=0) variational_loss = reduce_sum(residual_elements) # sum all residuals total_loss = variational_loss + beta * dirichlet_loss # Final loss\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "Algorithm 2 details a method for stacking input tensors to compute all gradients in a single backpropagation step, enabling efficient loss calculation for a domain composed of regular elements. The assembly process for the premultiplier matrices is described in the Appendix.\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "Though the method we mentioned earlier results in notable speed enhancements, it operates under the premise that the Jacobian remains constant for every element. While this assumption is true for regular elements, it becomes less applicable when dealing with skewed quadrilaterals. In such scenarios, the Jacobian may vary at distinct integration points (quadrature points) and for each shape function.\n",
      "To effectively tackle this challenge, it is essential to have a unique pre-multiplier matrix which stores the the gradients of the actual elements after transformation. However, using this strategy leads to a process that requires looping through each element to calculate loss, similar to the methodology outlined in Algorithm 1. This renders the previous optimization unfeasible for domains with skewed elements.\n",
      "In this section, we present a novel approach known as FastVPINNs. This technique stacks the pre-multiplier matrices into a three-dimensional array, or third-order tensor, with dimensions N elem × N test × N quad . The neural network solutions are structured into a two-dimensional matrix sized N quad × N elem . This configuration facilitates specific\n",
      "operations using tensors, where each layer of the tensor (representing each element) is systematically multiplied by the corresponding column of the matrix of solution gradients. The result is a set of residual vectors, each of size N test × 1 for every element. These vectors populate the columns of a final residual matrix sized N test × N elem , as illustrated in Figure 6. However, to calculate residuals element-wise using basic linear algebra subprograms (BLAS) such as tensor-matrix multiplication, it is necessary to transpose the dimensions of the solution gradients to N elem × N quad . This adjustment enables the utilization of TensorFlow's Abadi et al. (2015) tf.linalg.matvec function for efficient multiplication of tensor-matrix, resulting in a residual matrix of size N elem × N test . Subsequently, this matrix can be transposed to achieve the desired layout of N test × N elem .\n",
      "The FastVPINNs approach offers several significant benefits:\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "· Handles Complex Geometries: Through the manipulation of tensors, this approach eliminates the necessity of iterating through individual elements, even when working with complex geometries.\n",
      "· Efficient Loss Computation with BLAS: The loss computation, being formulated as tensor-based operations, is well-suited for GPU computations using BLAS routines. Additionally, GPUs typically have tensor cores designed specifically for tensor-based calculations, allowing these routines to leverage optimized hardware capabilities.\n",
      "· Requires Only One Backpropagation Pass: In contrast to existing approaches that require multiple backpropagation to compute gradients, FastVPINNs accomplishes this in a single step even for complex geometries.\n",
      "Figure 6: FastVPINNs Tensor schematic representation for residual computation.\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "Algorithm 3: Generalised Tensor-based FastVPINNs Algorithm # Compute the prematrix multipliers for testFunction and gradients # Obtain test fn and gradients in actual element and stack them # to form a tensor of shape N_elem x N_test x N_quad test_tensor = tf.stack(test_fn , axis=0) grad_x_tensor = tf.stack(grad_x_mat_list , axis=0) grad_y_tensor = tf.stack(grad_y_mat_list , axis=0) # Compute Forcing Matrix similar to Algorithm 2 def train_step(): # obtain solution for the quadrature points in entire domain sol = model(quad_points_in_domain) # obtain gradients and reshape them u_x, u_y = model.get_gradients().reshape(N_elem , N_quad) # Perform tensor -matrix mult to evaluate the integral grad_x = tf.transpose(tf.matvec(grad_x_tensor , u_x)) grad_y = tf.transpose(tf.matvec(grad_y_tensor , u_y)) # Subract the forcing matrix from diff to get residual residual_matrix = grad_x + grad_y -F # obtain mse error for each element in domain residual_elements = reduce_mean(square(residual_matrix), axis=0) # sum residuals of all elem in domain variational_loss = reduce_sum(residual_elements) total_loss = variational_loss + beta * dirichlet_loss\n",
      "Algorithm 3 summarizes the approach for FastVPINNs framework. In the next section, we assess the performance of the proposed FastVPINNs framework.\n",
      "Page content: 4.5 Experimental Setup and Design\n",
      "In the present research, every experiment was conducted on a system that boasts an NVIDIA RTX A6000 GPU with 48 GB of device memory. The NVIDIA-Modulus library (NVIDIA, 2023) was used for physics-informed neural networks (PINN). To establish a baseline comparison with hp-VPINNs, we use the cutting-edge hp-VPINNs code available on GitHub (Kharazmi, 2023). To ensure uniformity in all our experiments, we opted for the same kind of Jacobi polynomials as outlined in (Kharazmi et al., 2021). These polynomials, denoted as P n for degree n , follow the equation P n = P n +1 -P n -1 . We also integrated the Gauss-Jacobi-Lobatto quadrature for numerical integration in our computations. The hp-VPINNs software generally functions using exttttf.float64 precision for floating-point computations. However, our code is compatible with both tf.float64 and the slightly less accurate tf.float32 . In all our experiments, we employed tf.float32 , except when stated otherwise. The duration of each experiment was recorded using the time.time() function\n",
      "in Python. In the following sections, the phrase 'residual points' will refer to the collocation points in PINNs and the quadrature points used in hp-VPINNs and FastVPINNs..\n",
      "Initially, we conduct a comparison between the accuracy of FastVPINNs and PINNs, and delve into the impact of h- and p-refinement on the convergence of FastVPINNs in Section 4.6.1. The duration of training of PINNs, hp-VPINNs, and FastVPINNs is compared in Section 4.6.2. The efficacy of PINNs and FastVPINNs in dealing with high-frequency solution problems is examined in Section 4.6.3. The capability of FastVPINNs to tackle forward problems in intricate geometries is exhibited in Section 4.6.4. Lastly, the performance of FastVPINNs in resolving inverse problems in intricate geometries is probed in sections 4.7.1 and 4.7.2.\n",
      "Page content: 4.6 Evaluation of FastVPINNs\n",
      "Initially, we evaluate our code's efficacy on forward problems by solving the two-dimensional Poisson's equation within the unit square, using the specified forcing function\n",
      "\n",
      "This problem has the exact solution,\n",
      "\n",
      "To evaluate the effectiveness of the suggested solver in different solution frequencies, we run the code with ω = 2 π, 4 π and 8 π . The exact solutions for these cases are illustrated in Figure 7.\n",
      "Figure 7: Exact solutions of the two-dimensional Poisson's equation for given test-cases.\n",
      "Page content: 4.6.1 Accuracy Test\n",
      "In this section, we evaluate the accuracy of the proposed FastVPINNs framework by comparing it with the conventional PINNs technique on a problem where the parameter ω is set to 2 π . This comparative analysis involves both methodologies, using neural networks\n",
      "composed of three hidden layers, each containing 30 neurons. The FastVPINNs solution is derived using a grid of 2 × 2 elements, each element encompassing 40 × 40 quadrature points and 15 test functions per direction. The PINNs framework is trained using a total of 6400 collocation points, which corresponds to the total number of quadrature points employed in FastVPINNs. Both methodologies were trained for 100,000 iterations. The accuracy of their results was evaluated using a grid of 100 × 100 uniformly distributed points.\n",
      "Figure 8: Accuracy comparison between PINNs and FastVPINNs. The quadrature points used to train FastVPINNs are shown in (a). The FastVPINNs prediction is shown in (b) and the point-wise error for the FastVPINNs solution is shown in (c). The PINNs is trained on collocation points as shown in (d). The PINNs solution and point-wise error are shown in (e) and (f), respectively.\n",
      "As illustrated in Figure 8, the results show that FastVPINNs can reach a comparable level of accuracy as traditional PINNs. Furthermore, it is highlighted that the accuracy of FastVPINNs can be enhanced via h- and p-refinement.\n",
      "Page content: 4.6.1 Accuracy Test\n",
      "The impact of h-refinement is examined using an example where ω = 4 π . The process begins with a single element, after which the domain is partitioned into 4 × 4 grids, and then into 8 × 8 grids, while keeping the number of quadrature points per element constant at 80 × 80 and using five test functions in each direction within each element. The model has difficulty accurately depicting the shape or magnitude of the solution when only one element is used. However, when the grid is expanded to 8 × 8 elements, the error is significantly reduced to approximately O (10 -3 ), as illustrated in Figure 9(a). In the case of p-refinement, increasing the number of test functions in a 1 × 1 element grid from 5 × 5 to 20 × 20 reduces the error from O (10 ) to 0 O (10 -2 ), as depicted in Figure 9(b), thereby proving the effectiveness\n",
      "of p-refinement. A detailed error analysis for both h-refinement and p-refinement is provided in the Appendix B.1.\n",
      "Figure 9: Left: Effect of p-refinement(left) and h-refinement(right) on FastVPINNs.\n",
      "Page content: 4.6.2 Efficiency Test: Comparison of FastVPINNs with PINNs and Hp-VPINNs\n",
      "In this section, we assess the performance of our FastVPINNs framework by comparing it with two alternative methods: PINNs and the original version of hp-VPINNs. To measure computational proficiency, we recorded the duration needed to finish one training cycle for each framework. The evaluations were performed over 1,000 cycles to determine the median duration consumed. The results of the comparision are portrayed in Figure 10(a), where the x-axis indicates the count of residual points used for the calculations (collocation points for PINN and quadrature points for hp-VPINN) in addition to the total count of elements taken into account. For both hp-VPINNs and FastVPINNs, we applied five test functions on the xand y-axes, culminating in a sum of 25 quadrature points per element and 25 test functions in total. This experimental arrangement facilitates a straightforward efficiency comparison between FastVPINNs and PINNs, using the count of collocation points (quadrature) as a shared factor. The results depicted validate that FastVPINNs surpass both PINNs and the original version of hp-VPINNs library in terms of training time, regardless of whether tf.float32 or tf.float64 precision is employed.\n",
      "In contrast to the linear rise in training time observed with the increase in elements for the original version of hp-VPINNs, FastVPINNs demonstrate a nearly steady training time up to 400 elements, as depicted in Figure 10(b)\n",
      "Section 4.8 provides additional understanding regarding the influence of different hyperparameters such as the count of test functions, quadrature points, and elements on the training duration of FastVPINNs.\n",
      "Page content: 4.6.3 Performance of FastVPINNs on higher frequency problems\n",
      "Spectral bias is a phenomenon that describes the slower learning rate of neural networks for higher frequencies compared to lower frequency solutions during the training process Cao et al. (2020). The h-refinement technique can confine test functions to a more restricted area within our domain, enabling the network to detect higher frequency solutions in that\n",
      "Figure 10: (a) Variation of computational time with the number of quadrature (residual) points, plotted against the median time taken per epoch; (b) Comparison of computational time between hp-VPINNs and FastVPINNs for varying numbers of elements.\n",
      "specific area Kharazmi et al. (2021). In contrast to hp-VPINNs, which face longer training durations with an increased number of elements, the capability of FastVPINNs to sustain a consistent training time offers computational benefits for problems typified by higherfrequency solutions.\n",
      "The aim of this section is to assess and contrast the efficacy of PINNs and FastVPINNs when dealing with solutions of varying frequencies, while keeping the number of residual points constant. In the FastVPINN scenario, the h-refinement will be adjusted according to the solution's frequency. For example, for a solution frequency of ω = 2 π , a 2x2 element set-up will be used, each comprising 40x40 quadrature points. If the frequency is ω = 4 π , the setup will be modified to 4x4 elements, each with 20x20 quadrature points, and so on. FastVPINNs uses five test functions in each direction. It is important to emphasize that the total count of quadrature points will remain fixed at 6,400 for all FastVPINNs configurations, equaling the number of collocation points used for PINNs training. Both models use the same parameters: 1000 Dirichlet boundary points, a neural network with\n",
      "three hidden layers, each containing 30 neurons, trained over 100,000 iterations with a constant learning rate of 0.001 using the Adam optimizer Kingma and Ba (2014)\n",
      "Figure 11: (a) Comparing MAE for PINNs and FastVPINNs over different frequencies. (b) time taken for PINNs and FastVPINNs to reach an MAE of 5 × 10 -2 for different frequencies.\n",
      "Page content: 4.6.3 Performance of FastVPINNs on higher frequency problems\n",
      "Figure 11(a) demonstrates that FastVPINNs consistently outperform PINNs in Mean Absolute Error (MAE) across all tested frequencies, emphasizing the benefits of h-refinement. Furthermore, FastVPINNs reach the MAE target threshold more rapidly than traditional PINNs, as illustrated in Figure 11(b), highlighting their superior speed and accuracy. This also underscores the importance of carefully selecting hyperparameters such as N elem , N test , and N quad for FastVPINNs to optimize convergence and achieve efficiency and accuracy surpassing conventional PINNs.\n",
      "Page content: 4.6.4 FastVPINNs on Complex Geometries\n",
      "In order to assess the proficiency of the FastVPINN framework in handling intricate domains with a large number of elements, we used it in a 2D convection-diffusion problem (12)on a spur gear domain (Ω gear ) depicted in Figure 3. The gear mesh, made up of 14,192 quadrilateral cells, was created using Gmsh(Geuzaine and Remacle (2009)).\n",
      "\n",
      "where\n",
      "\n",
      "During this experiment, we used four testing functions per direction and assigned 25 quadrature points to each component. This setup resulted in a total of 354,800 quadrature points, plus an extra 6,096 points specifically for the Dirichlet boundary ( ∂ Ω gear ). The neural network was made up of 3 layers, each layer containing 50 neurons, and was launched with an initial learning rate of 0.005. This rate was adjusted through a method that reduced\n",
      "it by a factor of 0.99 for every 1,000 training iterations. The model was trained for a total of 150,000 iterations.\n",
      "Figure 12: (a) Exact Solution obtained using FEM. (b) Predicted solution-FastVPINNs (c) Pointwise absolute error.\n",
      "Figure (12) shows the exact and predicted solution along with the absolute point error. It should be noted that the model training was remarkably quick, finishing in less than 35 minutes, and each iteration took approximately 13 milliseconds. This highlights the efficiency of FastVPINNs in solving problems in domains with larger element counts and skewed elements, which are challenging for the original version of hp-VPINNs. The comparison of prediction times between FEM and FastVPINNs for varying numbers of degrees of freedom (DOFs) is discussed in Appendix B.2.\n",
      "Page content: 4.7 Investigating Inverse Problems with FastVPINNs\n",
      "In PINNs, inverse problems involve the use of neural networks to infer unidentified PDE parameters, aided by observed solutions at scattered data points, usually in complex physical systems. By enhancing the loss function with data from sensor points scattered across the 2D domain, the network is capable of simultaneously ascertaining the solution to the Poisson equation and the value of the parameter ϵ . Consequently, the loss function for this issue is formulated as follows.\n",
      "\n",
      "In this context, L s denotes the loss term that arises from the discrepancy between observed solutions at sensor points and their corresponding predictions from the neural network. The terms L v and L b represent the variational loss and the boundary loss, respectively, as indicated in (11). The hyperparameters τ and γ are adjusted to suit the specific problem and the chosen architecture. This study investigates two separate categories of inverse problems related to predicting diffusion parameters: one involves uniform diffusion parameter prediction in a Poisson-2D problem, and the other involves space-dependent diffusion parameter prediction in a Convection-Diffusion-2D problem.\n",
      "Page content: 4.7.1 Estimating Constant Diffusion Parameters\n",
      "In the context of uniform parameter inverse problems, we consider a two-dimensional (2D) Poisson equation as given in Eq. (13). The objective is to predict the constant diffusion parameter, denoted as ϵ , and the corresponding solution u x ( ).\n",
      "Figure 13: Schematics of VPINNs for space dependent inverse parameter modelling.\n",
      "\n",
      "Suppose the epsilon ( ) is spatially invariant, ϵ we can incorporate it as a single trainable variable within the FastVPINNs framework. To demonstrate this approach, we built a FastVPINN with a 30 × 3 neural network architecture, 50 randomly distributed sensor points, a 2 × 2 element domain discretization, and 40 × 40 quadrature points per element. The exact solution to this problem is u x, y ( ) = 10sin( x ) tanh( x e ) -ϵx 2 . The initial guess of epsilon ( ϵ initial ) is taken as 2, and the actual value of epsilon ( ϵ actual ) is 0.3. Training is carried out until it reaches the convergence criteria of | ϵ predicted -ϵ actual | < 10 -5 . The network converged in 8909 epochs with a mean absolute error of the solution at 6 6 . × 10 -2 . The total training time was close to 18 s with a mean time per epoch of 2 ms. Figure 14 presents the exact and predicted values of both the solution and ϵ .\n",
      "Page content: 4.7.2 Predicting Space-Dependent Diffusion Parameters\n",
      "This section addresses the more challenging case of predicting space-dependent parameters in partial differential equations (PDEs). As illustrated in Figure 13, the architecture of the neural network is modified to output both the solution and the space-dependent diffusion parameter at each point, enabling their simultaneous prediction. The network is guided by sensor point data, which are substituted here with the exact solution to accurately determine both the solution and its corresponding diffusion parameter. In this example, we consider a two-dimensional (2D) convection-diffusion equation as shown in Equation (14), solved on a circular domain using 1024 quadrilateral elements.\n",
      "\n",
      "where\n",
      "\n",
      "Figure 14: Inverse problem on FastVPINNs with constant diffusion parameter.\n",
      "15 shows the reference FEM solution, FastVPINNs solution and the corresponding pointwise error for both solution and ϵ . We observe that the FastVPINNs framework can reasonably predict both the solution and the spatially varying diffusion parameter with errors of the order of O (10 -2 )\n",
      "Page content: 4.8 Impact of Hyperparameters on FastVPINNs' Performance\n",
      "To conclude our evaluation of FastVPINNs, we investigated the impact of three critical hyperparameters on training time using a Poisson2D problem as an example. These hyperparameters are: N quad (quadrature points per element), N test (shape functions per element), and N elem (number of elements). All experiments utilized a neural network architecture consisting of 30 layers with 3 neurons each, and conducted over 1000 training iterations. The median time per epoch was used for data visualization. Figure 16(a) illustrates the relationship between N test and N quad for a fixed N elem of 1, showing that the training time per epoch remains relatively constant regardless of the number of N test functions, up to 10,000 quadrature points. Beyond this threshold, an increase in training time becomes noticeable, which depends on the parameters involved. Figure 16(b) shows the impact of varying N test and N elem with a fixed N quad of 100 per element. Here, the execution time remains stable across different N test functions until the number of elements reaches 100, beyond which it begins to increase. Figure 16(c) shows the effects of varying N quad and N elem while maintaining a constant N test of 100 per element. Figures suggest that while the overall memory occupied by the tensors might not change for certain\n",
      "Figure 15: (a) Exact solution( u ) obtained from FEM(ParMooN). (b) Predicted SolutionFastVPINNs. (c) Absolute error: FEM vs FastVPINNs solution. (d) Exact solution diffusion parameter( ϵ actual ). (e) Predicted diffusion parameter by FastVPINNs( ϵ predicted ) (f) Absolute error: ϵ actual vs ϵ predicted .\n",
      "combinations of N test and N quad , the number of quadrature points ( N quad ) has a more pronounced impact on training time compared to the number of test functions ( N test ). This observation can be attributed to the tensor-based loss computation, which performs a reduction operation along the N quad dimension, thereby underscoring the importance of N quad in influencing training time.\n",
      "Page content: 5 Conclusion\n",
      "In this work, we addressed the existing challenges of hp-VPINNs, which excel in capturing high-frequency solutions but struggle with the extended training times associated with problems involving a large number of elements and complex geometries. We introduced FastVPINNs, a novel framework that employs tensor-based computations to significantly reduce training time dependence on the number of elements and to efficiently handle complex meshes. We demonstrated a 100x speedup compared to the existing hp-VPINNs implementation. Additionally, with proper hyperparameter selection, FastVPINNs can surpass state-of-the-art PINN codes in both speed and accuracy. Our method's ability to manage complex geometries with a large number of elements was showcased by solving a forward problem on a 14,000-element gear quad mesh. We successfully solved inverse problems in complex domains, as evidenced by estimating a diffusion parameter in a circular domain with 1,024 elements. This task was completed in less than 200 seconds for 100,000 epochs, which would have taken hours with the existing hp-VPINNs implementation. We also examined how hyperparameters, such as the number of test functions ( N test ), quadrature\n",
      "Figure 16: Comparative analysis of the median training time per epoch for different hyperparameters: (a) Number of test functions ( N test ) vs Number of quadrature points ( N quad) with ( N elem =1), (b) Number of Elements ( N elem ) vs Number of test functions ( N test ) with quadrature points fixed at 10x10 ( N quad =10*10), (c) Number of elements ( N elem ) vs Number of quadrature points ( N quad ) with fixed number of test functions ( N test =10*10).\n",
      "points ( N quad ), and element count ( N elem ), influence the training time. This analysis offers valuable insights for selecting the most suitable hyperparameters for specific problems. The versatility of FastVPINNs unlocks its potential for real-world applications in fields such as fluid dynamics, where complex geometries and massive datasets are prevalent. Looking ahead, we aim to expand the capabilities of FastVPINNs to include triangular elements and 3D domains, further broadening its impact in scientific and engineering fields.\n",
      "Page content: Acknowledgments and Disclosure of Funding\n",
      "We thank Shell Research, India, for providing partial funding for this project. We are thankful to the MHRD Grant No. STARS-1/388 (SPADE) for partial support. We acknowledge Pratham Sunkad, for his assistance in running experiments for this paper.\n",
      "Page content: References\n",
      "M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia,\n",
      "R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man' e, R. Monga, S. Moore,\n",
      "D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar,\n",
      "P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vi' egas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/ . Software available\n",
      "from tensorflow.org.\n",
      "D. W. Abueidda, Q. Lu, and S. Koric. Meshless physics-informed deep learning method for three-dimensional solid mechanics. International Journal for Numerical Methods in Engineering , 122(23):7182-7201, 2021.\n",
      "N. Baker, F. Alexander, T. Bremer, A. Hagberg, Y. Kevrekidis, H. Najm, M. Parashar, A. Patra, J. Sethian, S. Wild, K. Willcox, and S. Lee. Workshop report on basic research needs for scientific machine learning: Core technologies for artificial intelligence. 2 2019. doi: 10.2172/1478744. URL https://www.osti.gov/biblio/1478744 .\n",
      "W. Bangerth, R. Hartmann, and G. Kanschat. deal. II-a general-purpose object-oriented finite element library. ACM Transactions on Mathematical Software (TOMS) , 33(4): 24-es, 2007.\n",
      "Page content: References\n",
      "S. Cai, Z. Mao, Z. Wang, M. Yin, and G. E. Karniadakis. Physics-informed neural networks (PINNs) for fluid mechanics: A review. Acta Mechanica Sinica , 37(12):1727-1738, 2021.\n",
      "Y. Cao, Z. Fang, Y. Wu, D.-X. Zhou, and Q. Gu. Towards understanding the spectral bias of deep learning, 2020.\n",
      "S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, and F. Piccialli. Scientific machine learning through physics-informed neural networks: Where we are and what's next. Journal of Scientific Computing , 92(3):88, 2022.\n",
      "H. Eivazi, M. Tahani, P. Schlatter, and R. Vinuesa. Physics-informed neural networks for solving Reynolds-averaged Navier-Stokes equations. Physics of Fluids , 34(7), 2022.\n",
      "S. Ganesan and M. Shah. SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and preconditioned iterative methods. arXiv preprint arXiv:2007.00056 , 2020.\n",
      "S. Ganesan and L. Tobiska. Finite elements: Theory and algorithms . Cambridge University Press, 2017.\n",
      "C. Geuzaine and J.-F. Remacle. Gmsh: A 3-D finite element mesh generator with builtin pre- and post-processing facilities. International Journal for Numerical Methods in Engineering , 79(11):1309-1331, 2009. doi: https://doi.org/10.1002/nme.2579. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.2579 .\n",
      "E. Haghighat, M. Raissi, A. Moure, H. Gomez, and R. Juanes. A physics-informed deep learning framework for inversion and surrogate modeling in solid mechanics. Computer Methods in Applied Mechanics and Engineering , 379:113741, 2021.\n",
      "Page content: References\n",
      "E. Kharazmi. hp-VPINNs: High-performance variational physics-informed neural networks, 2023. URL https://github.com/ehsankharazmi/hp-VPINNs . Accessed: 2023-12-01.\n",
      "E. Kharazmi, Z. Zhang, and G. E. Karniadakis. Variational physics-informed neural networks for solving partial differential equations. arXiv preprint arXiv:1912.00873 , 2019.\n",
      "E. Kharazmi, Z. Zhang, and G. E. Karniadakis. hp-VPINNs: Variational physics-informed neural networks with domain decomposition. Computer Methods in Applied Mechanics and Engineering , 374:113547, 2021.\n",
      "R. Khodayi-Mehr and M. Zavlanos. Varnet: Variational neural networks for the solution of partial differential equations. In Learning for Dynamics and Control , pages 298-307. PMLR, 2020.\n",
      "D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR , abs/1412.6980, 2014. URL https://api.semanticscholar.org/CorpusID:6628106 .\n",
      "I. Lagaris, A. Likas, and D. Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. IEEE Transactions on Neural Networks , 9(5):987-1000, 1998. doi: 10.1109/72.712178.\n",
      "C. Liu and H. Wu. cv-PINN: Efficient learning of variational physics-informed neural network with domain decomposition. Extreme Mechanics Letters , 63:102051, 2023. ISSN 2352-4316. doi: https://doi.org/10.1016/j.eml.2023.102051. URL https://www. sciencedirect.com/science/article/pii/S2352431623000974 .\n",
      "L. Lu, X. Meng, Z. Mao, and G. E. Karniadakis. DeepXDE: A deep learning library for solving differential equations. SIAM review , 63(1):208-228, 2021a.\n",
      "Page content: References\n",
      "L. Lu, R. Pestourie, W. Yao, Z. Wang, F. Verdugo, and S. G. Johnson. Physics-informed neural networks with hard constraints for inverse design. SIAM Journal on Scientific Computing , 43(6):B1105-B1132, 2021b.\n",
      "Z. Mao, A. D. Jagtap, and G. E. Karniadakis. Physics-informed neural networks for highspeed flows. Computer Methods in Applied Mechanics and Engineering , 360:112789, 2020.\n",
      "NVIDIA. NVIDIA Modulus Documentation. https://docs.nvidia.com/deeplearning/ modulus/modulus-sym/index.html , 2023. Accessed: 2023-03-10.\n",
      "NVIDIA Modulus. https://developer.nvidia.com/modulus . Last accessed Jan 01, 2024.\n",
      "Page content: References\n",
      "A. F. Psaros, X. Meng, Z. Zou, L. Guo, and G. E. Karniadakis. Uncertainty quantification in scientific machine learning: Methods, metrics, and comparisons. Journal of Computational Physics , 477:111902, 2023.\n",
      "N. Radin, S. Klinkel, and O. Altay. Effects of variational formulations on physics-informed neural network performance in solid mechanics. PAMM , page e202300222, 2023.\n",
      "M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics , 378:686-707, 2019.\n",
      "J. D. Smith, Z. E. Ross, K. Azizzadenesheli, and J. B. Muir. HypoSVI: Hypocentre inversion with Stein variational inference and physics informed neural networks. Geophysical Journal International , 228(1):698-710, 08 2021. ISSN 0956-540X. doi: 10.1093/gji/ggab309. URL https://doi.org/10.1093/gji/ggab309 .\n",
      "U. Wilbrandt, C. Bartsch, N. Ahmed, N. Alia, F. Anker, L. Blank, A. Caiazzo, S. Ganesan, S. Giere, G. Matthies, et al. ParMooN-a modernized program package based on mapped finite elements. Computers & Mathematics with Applications , 74(1):74-88, 2017.\n",
      "M. Yang and J. T. Foster. hp-Variational Physics-Informed Neural Networks for Nonlinear Two-Phase Transport in Porous Media. Journal of Machine Learning for Modeling and Computing , 2(2), 2021.\n",
      "E. Zhang, M. Dao, G. E. Karniadakis, and S. Suresh. Analyses of internal structures and defects in materials using physics-informed neural networks. Science advances , 8(7): eabk0644, 2022.\n",
      "Page content: A.1 Bilinear Transformation\n",
      "Let b 0 ( -1 , -1), b 1 (1 , -1), b 2 (1 1), , b 3 ( -1 1) be the vertices , of the reference element ˆ , K see Figure 4. For any function u X ( ), we denote u X ( ) = u F ( k ( ˆ )) X = ˆ( ˆ ). u X Further, the derivatives of the function, ∂u/∂x and ∂u/∂y on the original element can be obtained in terms of the derivatives defined on the refernce element ∂u/∂ξ ˆ and ∂u/∂η ˆ as follows:\n",
      "\n",
      "\n",
      "\n",
      "we can express this relation as,\n",
      "\n",
      "where,\n",
      "\n",
      "Finally, we have Finally, we have\n",
      "\n",
      "where, D is the determinant of the Jacobian matrix\n",
      "Page content: A.2 Algorithm : Premultiplier Assembly for Algorithm 2\n",
      "Algorithm : hp-VPINNs vectorised code - Premultiplier Assembly\n",
      "# Compute the prematrix multipliers for shapefunctions and gradients # Shape: (N_test , N_quad) for j in range(N_test): for q in range(N_quad): ' V_k[j][q] = quad_wt[q] * v_k[j][q] # Premult. shape mat V_x[j][q] = quad_wt[q] * v_kx[j][q] # Premult. grad x mat V_y[j][q] = quad_wt[q] * v_ky[j][q] # Premult. grad y mat # Compute Forcing Matrix # Shape (N_Elem , N_Test) for n in range(N_elem): for j in range(N_test): for q in range(N_quad): # xi and eta are quadrature co-ordinates in reference domain x,y = fe.get_actual_coordinates(n,xi[q],eta[q]) F[n][j] += j[n][q] * qw[q] * force_fn(x,y) * test[j][q] # Collect the jacobian terms and stack them # Shape: (N_quad , N_elem) for q in range(N_quad): for n in range(N_elem): J_x[q][n] = j[n][q] / j_x[n][q] # Jacobian x matrix J_y[q][n] = j[n][q] / j_y[n][q] # Jacobian y matrix\n",
      "Page content: B.1 Effect of h- and p-refinement in FastVPINNs\n",
      "Figure 17: Effect of h-refinement on the accuracy of solving the two-dimensional Poisson equation. The first, second, and third columns are the domain decomposition, FastVPINNs solution, and pointwise test error, respectively. From top to bottom: N elem = 1, N elem = 16 and N elem = 64. For each element, we use 80 × 80 quadrature points and 5 test functions in each direction.\n",
      "Figure 18: Effect of p-refinement on the accuracy of solution of two-dimensional Poisson's equation on 1 element. The first and second columns are the FastVPINNs solution and point-wise test error, respectively. From top to bottom: N test = 5 × 5, N test = 10 × 10, N test = 15 × 15 and N test = 20 × 20. The element has 80 × 80 total quadrature points.\n",
      "Table 1: Time Taken (in s) for Prediction using FEM and PINNs\n",
      "Page content: B.1 Effect of h- and p-refinement in FastVPINNs\n",
      "Table 1: Time Taken (in s) for Prediction using FEM and PINNs\n",
      "29302, FEM = 2.638. 29302, PINNs = 7.807e-4. 115868, FEM = 13.0352. 115868, PINNs = 7.978e-4. 259698, FEM = 32.220. 259698, PINNs = 1.777e-3. 460792, FEM = 50.680. 460792, PINNs = 3.139e-3. 719150, FEM = 81.784. 719150, PINNs = 4.890e-3. 1034772, FEM = 172.967. 1034772, PINNs = 7.023e-3\n",
      "Page content: B.2 Time Comparison - FastVPINNs vs FEM\n",
      "The Table 1 and Figure 19 below represents the time required for the prediction of the solution using PINNs and FEM. It's important to note that for FastVPINNs, this time does not include the training time.\n",
      "Figure 19: Comparision of time taken for prediction by FEM and PINNs for varying number of quadrature points.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Directory to save the extracted images\n",
    "output_dir = '/home/parani/ibm/'# Modify this path to your preferred directory\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Iterate through the document to extract images\n",
    "for doc_idx, doc in enumerate(docs):\n",
    "    print(f\"Page content: {doc.page_content}\")\n",
    "    \n",
    "    if hasattr(doc, 'images') and doc.images:\n",
    "        for img_idx, img in enumerate(doc.images):\n",
    "            try:\n",
    "                # Check if the image data is byte-like or file path and handle accordingly\n",
    "                if isinstance(img, bytes):  # Byte data\n",
    "                    img_data = io.BytesIO(img)  # Convert byte data to a file-like object\n",
    "                    image = Image.open(img_data)  # Open image using Pillow\n",
    "                else:\n",
    "                    # If it's a file path, directly open the image (if possible)\n",
    "                    image = Image.open(img)\n",
    "\n",
    "                # Save the image as PNG or JPG\n",
    "                image_path = os.path.join(output_dir, f\"extracted_image_{doc_idx}_{img_idx}.png\")\n",
    "                image.save(image_path)\n",
    "                print(f\"Extracted image saved at: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content: FastVPINNs: Tensor-Driven Acceleration of VPINNs for Complex Geometries\n",
      "Thivin Anandh 1\n",
      "thivinanandh@iisc.ac.in\n",
      "Divij Ghose 1\n",
      "divijghose@iisc.ac.in\n",
      "Himanshu Jain 2\n",
      "ms19026@iisermohali.ac.in\n",
      "Sashikumaar Ganesan 1 ∗\n",
      "sashi@iisc.ac.in\n",
      "1 Department of Computational and Data Sciences\n",
      "Indian Institute of Science, Bangalore\n",
      "Karnataka, India\n",
      "2 Department of Physical Sciences\n",
      "Indian Institute of Science Education and Research, Mohali\n",
      "Punjab, India\n",
      "∗ Corresponding author\n",
      "No images found in doc 0.\n",
      "Page content: Abstract\n",
      "Variational Physics-Informed Neural Networks (VPINNs) utilize a variational loss function to solve partial differential equations, mirroring Finite Element Analysis techniques. Traditional hp-VPINNs, while effective for high-frequency problems, are computationally intensive and scale poorly with increasing element counts, limiting their use in complex geometries. This work introduces FastVPINNs, a tensor-based advancement that significantly reduces computational overhead and improves scalability. Using optimized tensor operations, FastVPINNs achieve a 100-fold reduction in the median training time per epoch compared to traditional hp-VPINNs. With proper choice of hyperparameters, FastVPINNs surpass conventional PINNs in both speed and accuracy, especially in problems with highfrequency solutions. Demonstrated effectiveness in solving inverse problems on complex domains underscores FastVPINNs' potential for widespread application in scientific and engineering challenges, opening new avenues for practical implementations in scientific machine learning.\n",
      "Keywords: Physics-informed neural networks, Variational physics-informed neural networks, Domain decomposition, hp-Variational physics-informed neural networks\n",
      "No images found in doc 1.\n",
      "Page content: 1 Introduction\n",
      "At present, the realm of applied mathematics is witnessing substantial progress as a result of incorporating deep learning approaches in solving partial differential equations (PDEs). These methods, collectively termed scientific machine learning (SciML) (Cuomo et al. (2022); Baker et al. (2019); Psaros et al. (2023)), often complement or replace traditional solvers. Despite the dominance of conventional numerical methods such as the finite element method (FEM), which boasts several open-source solvers (Wilbrandt et al. (2017); Bangerth et al. (2007); Ganesan and Shah (2020)), SciML has rapidly evolved. This evolution has led to a growing repertoire of accessible SciML libraries (Lu et al. (2021a); NVIDIA Modulus).\n",
      "Since the advent of physics-informed neural networks (PINNs) (Lagaris et al. (1998); Raissi et al. (2019)), the application of such methods has surged. PINNs enhance the\n",
      "typical data-driven loss function of neural networks by incorporating an additional term that minimizes the residual of the underlying PDE and enforces physics-based constraints. Features such as the ease of obtaining gradients through automatic differentiation, and the ability to train networks for both forward and inverse modeling, make PINNs superior to traditional methods (Abueidda et al. (2021); Lu et al. (2021b)). Consequently, PINNs have found widespread application in various fields, including solid mechanics (Haghighat et al. (2021); Zhang et al. (2022)), fluid mechanics (Mao et al. (2020); Cai et al. (2021); Eivazi et al. (2022)), and geophysics (Smith et al. (2021)).\n",
      "An extension of PINNs, Variational PINNs (VPINNs), utilize the weak form of the PDE in their loss functions, mirroring the Petrov-Galerkin framework used in conventional FEM (Kharazmi et al. (2019); Khodayi-Mehr and Zavlanos (2020)). Despite their computational demand due to the necessity to numerically compute integrals in the loss function, VPINNs represent a significant step forward in applying neural networks to PDEs.\n",
      "No images found in doc 2.\n",
      "Page content: 1 Introduction\n",
      "Based on VPINN, hp-VPINNs have been developed to improve accuracy through domain decomposition (h-refinement) or increasing polynomial order (p-refinement) (Kharazmi et al. (2021)). Although hp-VPINNs offer superior accuracy in various problems, they suffer from critical limitations that hinder their practical application. These limitations include their computational complexity, linear scaling of training time with element count, and difficulty in handling complex geometries with skewed elements. These issues are evidenced in both academic and practical scenarios and have been a barrier to greater adoption despite various attempts to deploy hp-VPINNs in different applications (Radin et al. (2023); Yang and Foster (2021)).\n",
      "Furthermore, recent developments such as convolutional PINNs (cv-PINNs) (Liu and Wu (2023)) introduced convolutional operations to accelerate the training of hp-VPINNs. Despite claims of superior performance, cv-PINNs still exhibited linear increases in training time with element count in 1D studies, and their solutions have been limited to domains suitable for decomposition into regular quadrilateral cells.\n",
      "In response to these challenges, this work introduces FastVPINNs, a novel framework designed to address the limitations of hp-VPINNs. The proposed FastVPINNs leverage tensor-based operations to compute the loss, substantially reducing training times and diminishing the impact of increasing element counts. This advancement enables the handling of complex geometries, significantly broadening the practical applicability of our approach.\n",
      "No images found in doc 3.\n",
      "Page content: 2.1 Governing Equations\n",
      "Consider a two-dimensional steady-state convection-diffusion equation:\n",
      "\n",
      "Here, x ∈ Ω, ε , and b are the diffusion coefficient and convective velocity, respectively. In addition, f ( x ) is a known source function with appropriate smoothness. The Dirichlet boundary condition u x ( ) = g x ( ) is imposed on the domain boundary ∂ Ω. The two-dimensional steady-state Poisson equation can be obtained from (1) by substituting b = (0 0) , T and\n",
      "ε = 1.\n",
      "\n",
      "For the remainder of our discussion in this section, we will be using (2) as a reference.\n",
      "No images found in doc 4.\n",
      "Page content: 2.2 Physics Informed Neural Networks\n",
      "The result generated by a deep neural network is typically structured as a parametric function of the variable x , denoted as u NN ( x W,b ; ). In this context, W and b represent the weights and biases of the network. When the neural network consists of h hidden layers, with the i th layer containing n i neurons, the mathematical representation of the function takes the following shape:\n",
      "\n",
      "Here, l : R n h → R is a linear mapping in the output layer and T ( ) i ( ) = · σ W ( ( ) i ×· + b ( ) i ) is a non-linear mapping in the i th layer ( i = 1 2 , , · · · , h ), with the non-linear activation function σ and the weights W ( ) i and biases b ( ) i of the respective layers.\n",
      "The neural network's output u NN ( x W,b ; ) can serve as an approximation to the unknown solution u x ( ) of the equation 2 by training the deep neural network. Physics-Informed Neural Networks aim to achieve this estimation by systematically reducing the residual arising from the governing equations specified in equation 2 with u NN ( x W,b ; ). Specifically, we refer to the residual related to the partial differential equation (PDE) and the boundary conditions as P and B , respectively, that is,\n",
      "\n",
      "The loss function employed in the neural network architecture is designed to integrate two primary components: a Partial Differential Equation (PDE) loss and a boundary loss. These components are defined at particular training points within the domain to reduce inaccuracies associated with the PDE and boundary constraints. This division of the loss function allows for a focused reduction in the difference between the neural network's forecasts and the expected physical phenomena described by the governing equations and boundary constraints. In particular, we define\n",
      "\n",
      "where N T is the total number of training points in the interior of the domain Ω, N D is the total number of training points on the boundary ∂ Ω and τ is a scaling factor applied to control the penalty on the boundary term.\n",
      "where\n",
      "No images found in doc 5.\n",
      "Page content: 2.3 hp-Variational Physics Informed Neural Network\n",
      "In this section, we initially establish the variational form of the Poisson equation (2), followed by introducing the Variational Physics Informed Neural Network. Let H (Ω) denote 1 the conventional Sobolev space, and define\n",
      "\n",
      "The subsequent procedure consists of taking the equation (2), multiplying it by v ∈ V , integrating over Ω, and then utilizing integration by parts on the second derivative term. For more detailed information, please refer to (Ganesan and Tobiska (2017)). Consequently, the variational representation of the Poisson equation can be formulated as:\n",
      "Find u ∈ V such that,\n",
      "\n",
      "\n",
      "The domain Ω is then divided into an array of non-overlapping cells, labeled as K k , where k = 1 2 , , . . . , N elem , ensuring that the complete union ⋃ N elem k =1 K k = Ω covers the entire domain Ω. In this context, we define V h as a finite-dimensional subspace of V , spanned by the basis functions ϕ h := { ϕ j ( x ) } , j = 1 2 , , . . . , N test , where N test indicates the total number of basis functions in V h . As a result, the discretized variational formulation related to equation (6) can be written as follows,\n",
      "Find u h ∈ V h such that,\n",
      "\n",
      "where\n",
      "\n",
      "These integrals can be approximated by employing a quadrature rule, leading to\n",
      "\n",
      "Here, N quad is the number of quadrature points in a cell.\n",
      "The hp-Variational Physics Informed Neural Networks (hp-VPINNs) framework, as presented by Kharazmi et al. (2021), utilizes specific test functions v k , where k ranges from 1 to N elem, that are localized and defined within individual non-overlapping cells across the domain.\n",
      "̸\n",
      "\n",
      "Here, v p represents a polynomial function of degree p . This selection of test and solution spaces results in a Petrov-Galerkin finite element method. Specifically, u h is estimated by u NN ( x W,b ; ), which is the neural network solution, whereas the test function v h is a predetermined polynomial function. By utilizing these functions, we establish the cell-wise residual of the variational form (7) with u NN ( x W,b ; ) as\n",
      "\n",
      "Further, define the variational loss by\n",
      "\n",
      "No images found in doc 6.\n",
      "Page content: 2.3 hp-Variational Physics Informed Neural Network\n",
      "and the cost function of the neural network in hp-VPINN as\n",
      "\n",
      "Here, L b is the Dirichlet boundary loss as expressed in (5) and τ is a scaling factor applied to control the penalty on the boundary term.\n",
      "Remark: The only distinction between VPINNs and hp-VPINN resides in the selection of the test function. Within the framework of VPINNs, a polynomial that has global support throughout the domain is employed as a test function. Conversely, in the context of hpVPINN, a compilation of polynomials, each offering support on an element-wise basis, is utilized. Figure 1 represents the schematic of VPINNs for a 2D Poisson problem.\n",
      "No images found in doc 7.\n",
      "Page content: 3 Implementation of hp-VPINNs\n",
      "This section focuses on the existing implementation of hp-VPINNs. Initially, we explain the current approach to calculating the variational loss in hp-VPINNs using numerical integration methods like Gauss-Lobatto or Gauss-Legendre to achieve accurate integral approximations. Next, we will examine two key limitations of the existing implementation. Firstly, we will explore why the current approach leads to longer training times. Secondly, we will discuss why it may not be suitable for problems involving complex shapes.\n",
      "No images found in doc 8.\n",
      "Page content: 3.1 Overview of Current hp-VPINNs Implementation\n",
      "To calculate the cost function related to hp-VPINNs, as specified in Equation 11, it is essential to estimate the integration outlined in Equation 9. This estimation is accomplished by utilizing numerical integration methods, with the Gauss-Lobatto and Gauss-Legendre quadrature methods being particularly effective. As a result of applying these numerical techniques to the integral over the cell K k , W k ( x W,b ; ) becomes\n",
      "\n",
      "Here, N quad denotes the number of quadrature points in a given element K k .\n",
      "Algorithm 1: hp-VPINNs Implementation in Kharazmi et.al\n",
      "No images found in doc 9.\n",
      "Page content: 3.1 Overview of Current hp-VPINNs Implementation\n",
      "# VPINNs Existing Implementation def train_step(): for k in N_elem: u_NN = model(quadrature_points_in_curr_element) # get NN output u_x, u_y = model.get_grad(u_NN) # get sol gradients NN v_kx , v_ky = fem.get_grad(v_k) # get test fn grad j,j_x,j_y = fem.get_jacobians(K_k) # get jacobians w = fem.get_quad_wt(v_k, K_k) # get quad wt r[] = 0 # compute PDE loss for q in N_quad: # number of test functions for j in N_test: # number of quadrature points grad_x = (j[q]/j_x[q])*w[q]*u_x[q]*v_kx[q][j] # du/dx.dv/dx grad_y = (j[q]/j_y[q])*w[q]*u_y[q]*v_ky[q][j] # du/dy.dv/dy r[j] += (grad_x + grad_y -F[q][j]) # Var loss (F is precomputed outside train loop) variational_loss += reduce_mean(square(r)) dirichlet_loss = reduce_mean(square(model(input_bound_pts) -bd_actual) total_loss = variational_loss + tau * dirichlet_loss # Total loss\n",
      "No images found in doc 10.\n",
      "Page content: Nomenclature:\n",
      "v kx, v ky : gradients of the test functions in the x and y directions at the k-th cell. u x, u y : gradients of u NN in the x and y directions (computed using AutoDiff). j[q] : Jacobian of the element at the specified quadrature point. j x[q] , j y[q] : Jacobian of the element at the specified quadrature point in the x and y directions.\n",
      "Algorithm 1 describes the approach for quantifying the loss function in the context of hp-VPINNs, following the guidelines provided in the GitHub repository (Kharazmi (2023)). This approach involves an iterative procedure that covers each element of the computational domain to compute the local PDE loss. Local losses are then combined to obtain the overall PDE loss measure. Central to this method is the need for gradients and function values of the test functions, which are obtained from predefined basis functions such as Jacobi polynomials. Simultaneously, the neural network provides solutions and gradients at specified points within each element. After computing the local losses, the algorithm consolidates these losses from all elements and combines them with the prescribed boundary loss, as detailed in equation (9). This unified loss function is crucial for training the neural network, ensuring that the hp-VPINNs model is finely adjusted not only to the underlying physics described by the PDE but also to the specified boundary constraints.\n",
      "Figure 1: Schematics of Variational PINNs for a 2D Poisson problem.\n",
      "No images found in doc 11.\n",
      "Page content: 3.2 Need for Efficient hp-VPINNs Implementation\n",
      "hp-VPINNs employs h-refinement that restricts the test functions to smaller areas within the computational domain. This restriction of test functions allows hp-VPINNs to capture high frequency features in the solution. However, increasing the number of elements leads to a proportional increase in the time required to train the model.\n",
      "· Training time complexity : The training time of hp-VPINNs increases linearly with the addition of more elements, even when the total number of quadrature points remains constant throughout the domain, as demonstrated in Figure 2. Consequently, employing h-refinement, which involves adding more elements to handle rapidly changing solutions, does not provide the anticipated advantage, as it substantially increases the computational cost.\n",
      "· Handling complex geometries : The current version of hp-VPINNs is limited to operate with structured quadrilateral elements. This limitation stems from the current implementation using constant Jacobian values for each element to transform the gradients from the reference element to the actual element. However, practical applications often require skewed elements within complex domains as shown in Figure 3), where the Jacobian will not be constant within an element.\n",
      "No images found in doc 12.\n",
      "Page content: 4 FastVPINNs Methodology\n",
      "This section introduces FastVPINNs, a novel framework that significantly improves upon the existing hp-VPINNs. FastVPINNs tackles two critical challenges: handling complex geometries and achieving faster training times. We achieve these advancements through several key optimizations, including eliminating element-wise looping, removing redundant computations, and leveraging BLAS (Basic Linear Algebra Subprograms) routines. For\n",
      "Figure 2: hp-VPINNs: Effect of training time on Number of elements (a) Number of residual points vs training time.(Each element has 25 quadrature points, so 30K quadrature points will have 1200 elements).(b) Number of elements vs training time(total number of quadrature points within the domain is kept constant at 6400).\n",
      "Figure 3: Mesh of spur gear with 14,000 quad elements.\n",
      "handling complex geometries, we incorporate concepts of mapped finite elements by utilizing bilinear transformations.\n",
      "No images found in doc 13.\n",
      "Page content: 4.1 Mapped hp-VPINNs\n",
      "Complex geometric shapes frequently lead to the presence of irregular triangles or quadrilaterals in 2D, which pose challenges when it comes to accurately computing integrals and derivatives. To tackle this challenge, the FEM employs mapped finite elements. This approach converts all irregular elements in the actual domain into simpler shapes within a common reference element, as shown in Figure 4.\n",
      "The adoption of mapped finite elements offers several advantages:\n",
      "· The simplification of integrals and derivatives is achieved by moving these calculations to a reference element.\n",
      "· The need to compute gradients multiple times for each element is eliminated, as the reference gradients are consistent across all elements in the domain.\n",
      "In this work, the bilinear transformation is employed when dealing with quadrilateral elements. Further details on bilinear transformation can be found in the Appendix.\n",
      "Figure 4: Bilinear transformation.\n",
      "No images found in doc 14.\n",
      "Page content: 4.2 Optimization I: Enhancing Efficiency with Matrix-Vector Product Reformulation\n",
      "Upon a detailed analysis of Algorithm 1, it is evident that its computational procedure consists mainly of iterative multiplication operations. These operations pertain to the derivatives of test functions and the quadrature weights utilized for numerical integration, which remain constant throughout the training cycle. The only component that undergoes variation at each training step is the predicted solution and its gradients derived from the neural network. Recognizing this recurrent pattern, we've devised an approach to modify the gradient computation, denoted as grad x in Algorithm 1, to be expressed as a matrixvector product. Initially, a matrix is prepared in advance, known as the precomputed test function matrix. This matrix, sized N test × N quad , comprises pre-computed values obtained by multiplying each shape function by the corresponding quadrature weights. During the training process, this matrix is multiplied by the solution of the neural network and a scaling factor known as Jacobian. This multiplication yields a vector of residuals, with dimensions N test × 1. This has the following advantages.\n",
      "· Using BLAS for Faster Calculations: By organizing our loss computations in a matrix-vector format, we can utilize the BLAS (Basic Linear Algebra Subprograms) routines. These optimized routines are designed to operate efficiently on GPUs, enhancing the speed of our calculations.\n",
      "· Elimination of Redundant Calculations: Since the test function matrix is precomputed and remains unchanged during training, except for cases such as moving domain problems where the domain shape changes, it is not necessary to repeatedly compute the product of the derivatives of the shape functions and the quadrature weights at each training iteration. This efficient approach saves considerable time and\n",
      "computational resources, thereby improving the speed and effectiveness of the training process.\n",
      "No images found in doc 15.\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "Despite the efforts made to reduce redundant computations and optimize matrix vector operations, our algorithm still requires the individual processing of each element for the calculation of loss within the computational domain. This means that during every training iteration, the neural network must calculate the solution N elem times (known as forward passes) and then compute the gradients of these solutions another N elem times (known as backward passes) to determine the loss. This sequential process is a major factor that contributes to the slowdown in the training of hp-VPINNs. For basic non-distorted quadrilateral elements (similar to those shown in Figure 5), the Jacobian values are constant for a given element. Instead of computing the gradients individually for each element, a single reference gradient matrix can be computed and later multiplied with the corresponding Jacobians to obtain the actual gradients for each element.\n",
      "In our approach, we exploit these characteristics of a domain composed of regular elements to perform loss computation without the need to iterate through individual elements. The process involves gathering quadrature points, which are used for numerical integration, from all elements across the domain. These points are organized into a single input of dimensions ( N quad x N elem , 2) and then supplied as input to the neural network.Consequently, the neural network produces an output in the form of a vector that can be reorganized into a matrix of size N quad × N elem . Each column of this matrix represents the predicted results at the quadrature points for each element. Subsequently, we proceed by taking each column of this matrix and multiplying it by the corresponding Jacobian. The loss calculation now involves multiplying the premultiplier matrix (reference gradient) with the gradient matrix from the neural network, which is scaled by the Jacobian. The result of this multiplication produces a final matrix with dimensions N test × N elem , where each column represents the residuals computed for each element within the actual domain.\n",
      "The key advantages of this optimized approach include:\n",
      "No images found in doc 16.\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "· Single Backpropagation per Iteration: Through the aggregation of inputs from all elements, we are able to compute the gradients for all elements simultaneously, requiring only a single forward pass and one backward pass (for gradient calculation) across the neural network.\n",
      "· Elimination of Element Looping: By combining all inputs and using matrix multiplication, we avoid individually processing each element. This approach significantly accelerates our computations and enhances the overall computational efficiency.\n",
      "Algorithm 2: Vectorised hp-VPINNs with elimination of element looping\n",
      "# J_x, J_y: premultiplier jacobian matrices (N_quad , N_elem) # F : preassembled force function matrix (N_elem , N_test) # V : test function matrix (N_test , N_quad) # V_x, V_y: test function gradient matrices (N_test , N_quad)\n",
      "Figure 5: Quadrilateral meshes with elements having constant Jacobian.\n",
      "# NOTE : refer Appendix for pseudocode of pre-assembly matrices. def train_step(): u_NN = model(quadrature_points_in_curr_element) # get NN output # get gradients and reshape them u_x, u_y = model.get_gradients().reshape(N_quad , N_elem) # Multiply jacobians of corresponding elements to sol gradients # Perform mat-mat multiplication grad_x = matmul(grad_x_mat , u_x * J_x) # int(du/dx.dv/dx), grad_y = matmul(grad_y_mat , u_y * J_y) # int(du/dy.dv/dy) # obtain mse for each element by row reduction (axis 0) residual_elements = reduce_mean(square(grad_x + grad_y -F), axis=0) variational_loss = reduce_sum(residual_elements) # sum all residuals total_loss = variational_loss + beta * dirichlet_loss # Final loss\n",
      "No images found in doc 17.\n",
      "Page content: 4.3 Optimization II: Overcoming the Element Looping for regular elements\n",
      "Algorithm 2 details a method for stacking input tensors to compute all gradients in a single backpropagation step, enabling efficient loss calculation for a domain composed of regular elements. The assembly process for the premultiplier matrices is described in the Appendix.\n",
      "No images found in doc 18.\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "Though the method we mentioned earlier results in notable speed enhancements, it operates under the premise that the Jacobian remains constant for every element. While this assumption is true for regular elements, it becomes less applicable when dealing with skewed quadrilaterals. In such scenarios, the Jacobian may vary at distinct integration points (quadrature points) and for each shape function.\n",
      "To effectively tackle this challenge, it is essential to have a unique pre-multiplier matrix which stores the the gradients of the actual elements after transformation. However, using this strategy leads to a process that requires looping through each element to calculate loss, similar to the methodology outlined in Algorithm 1. This renders the previous optimization unfeasible for domains with skewed elements.\n",
      "In this section, we present a novel approach known as FastVPINNs. This technique stacks the pre-multiplier matrices into a three-dimensional array, or third-order tensor, with dimensions N elem × N test × N quad . The neural network solutions are structured into a two-dimensional matrix sized N quad × N elem . This configuration facilitates specific\n",
      "operations using tensors, where each layer of the tensor (representing each element) is systematically multiplied by the corresponding column of the matrix of solution gradients. The result is a set of residual vectors, each of size N test × 1 for every element. These vectors populate the columns of a final residual matrix sized N test × N elem , as illustrated in Figure 6. However, to calculate residuals element-wise using basic linear algebra subprograms (BLAS) such as tensor-matrix multiplication, it is necessary to transpose the dimensions of the solution gradients to N elem × N quad . This adjustment enables the utilization of TensorFlow's Abadi et al. (2015) tf.linalg.matvec function for efficient multiplication of tensor-matrix, resulting in a residual matrix of size N elem × N test . Subsequently, this matrix can be transposed to achieve the desired layout of N test × N elem .\n",
      "The FastVPINNs approach offers several significant benefits:\n",
      "No images found in doc 19.\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "· Handles Complex Geometries: Through the manipulation of tensors, this approach eliminates the necessity of iterating through individual elements, even when working with complex geometries.\n",
      "· Efficient Loss Computation with BLAS: The loss computation, being formulated as tensor-based operations, is well-suited for GPU computations using BLAS routines. Additionally, GPUs typically have tensor cores designed specifically for tensor-based calculations, allowing these routines to leverage optimized hardware capabilities.\n",
      "· Requires Only One Backpropagation Pass: In contrast to existing approaches that require multiple backpropagation to compute gradients, FastVPINNs accomplishes this in a single step even for complex geometries.\n",
      "Figure 6: FastVPINNs Tensor schematic representation for residual computation.\n",
      "No images found in doc 20.\n",
      "Page content: 4.4 FastVPINNs: Generalized algorithm for Complex Geometries\n",
      "Algorithm 3: Generalised Tensor-based FastVPINNs Algorithm # Compute the prematrix multipliers for testFunction and gradients # Obtain test fn and gradients in actual element and stack them # to form a tensor of shape N_elem x N_test x N_quad test_tensor = tf.stack(test_fn , axis=0) grad_x_tensor = tf.stack(grad_x_mat_list , axis=0) grad_y_tensor = tf.stack(grad_y_mat_list , axis=0) # Compute Forcing Matrix similar to Algorithm 2 def train_step(): # obtain solution for the quadrature points in entire domain sol = model(quad_points_in_domain) # obtain gradients and reshape them u_x, u_y = model.get_gradients().reshape(N_elem , N_quad) # Perform tensor -matrix mult to evaluate the integral grad_x = tf.transpose(tf.matvec(grad_x_tensor , u_x)) grad_y = tf.transpose(tf.matvec(grad_y_tensor , u_y)) # Subract the forcing matrix from diff to get residual residual_matrix = grad_x + grad_y -F # obtain mse error for each element in domain residual_elements = reduce_mean(square(residual_matrix), axis=0) # sum residuals of all elem in domain variational_loss = reduce_sum(residual_elements) total_loss = variational_loss + beta * dirichlet_loss\n",
      "Algorithm 3 summarizes the approach for FastVPINNs framework. In the next section, we assess the performance of the proposed FastVPINNs framework.\n",
      "No images found in doc 21.\n",
      "Page content: 4.5 Experimental Setup and Design\n",
      "In the present research, every experiment was conducted on a system that boasts an NVIDIA RTX A6000 GPU with 48 GB of device memory. The NVIDIA-Modulus library (NVIDIA, 2023) was used for physics-informed neural networks (PINN). To establish a baseline comparison with hp-VPINNs, we use the cutting-edge hp-VPINNs code available on GitHub (Kharazmi, 2023). To ensure uniformity in all our experiments, we opted for the same kind of Jacobi polynomials as outlined in (Kharazmi et al., 2021). These polynomials, denoted as P n for degree n , follow the equation P n = P n +1 -P n -1 . We also integrated the Gauss-Jacobi-Lobatto quadrature for numerical integration in our computations. The hp-VPINNs software generally functions using exttttf.float64 precision for floating-point computations. However, our code is compatible with both tf.float64 and the slightly less accurate tf.float32 . In all our experiments, we employed tf.float32 , except when stated otherwise. The duration of each experiment was recorded using the time.time() function\n",
      "in Python. In the following sections, the phrase 'residual points' will refer to the collocation points in PINNs and the quadrature points used in hp-VPINNs and FastVPINNs..\n",
      "Initially, we conduct a comparison between the accuracy of FastVPINNs and PINNs, and delve into the impact of h- and p-refinement on the convergence of FastVPINNs in Section 4.6.1. The duration of training of PINNs, hp-VPINNs, and FastVPINNs is compared in Section 4.6.2. The efficacy of PINNs and FastVPINNs in dealing with high-frequency solution problems is examined in Section 4.6.3. The capability of FastVPINNs to tackle forward problems in intricate geometries is exhibited in Section 4.6.4. Lastly, the performance of FastVPINNs in resolving inverse problems in intricate geometries is probed in sections 4.7.1 and 4.7.2.\n",
      "No images found in doc 22.\n",
      "Page content: 4.6 Evaluation of FastVPINNs\n",
      "Initially, we evaluate our code's efficacy on forward problems by solving the two-dimensional Poisson's equation within the unit square, using the specified forcing function\n",
      "\n",
      "This problem has the exact solution,\n",
      "\n",
      "To evaluate the effectiveness of the suggested solver in different solution frequencies, we run the code with ω = 2 π, 4 π and 8 π . The exact solutions for these cases are illustrated in Figure 7.\n",
      "Figure 7: Exact solutions of the two-dimensional Poisson's equation for given test-cases.\n",
      "No images found in doc 23.\n",
      "Page content: 4.6.1 Accuracy Test\n",
      "In this section, we evaluate the accuracy of the proposed FastVPINNs framework by comparing it with the conventional PINNs technique on a problem where the parameter ω is set to 2 π . This comparative analysis involves both methodologies, using neural networks\n",
      "composed of three hidden layers, each containing 30 neurons. The FastVPINNs solution is derived using a grid of 2 × 2 elements, each element encompassing 40 × 40 quadrature points and 15 test functions per direction. The PINNs framework is trained using a total of 6400 collocation points, which corresponds to the total number of quadrature points employed in FastVPINNs. Both methodologies were trained for 100,000 iterations. The accuracy of their results was evaluated using a grid of 100 × 100 uniformly distributed points.\n",
      "Figure 8: Accuracy comparison between PINNs and FastVPINNs. The quadrature points used to train FastVPINNs are shown in (a). The FastVPINNs prediction is shown in (b) and the point-wise error for the FastVPINNs solution is shown in (c). The PINNs is trained on collocation points as shown in (d). The PINNs solution and point-wise error are shown in (e) and (f), respectively.\n",
      "As illustrated in Figure 8, the results show that FastVPINNs can reach a comparable level of accuracy as traditional PINNs. Furthermore, it is highlighted that the accuracy of FastVPINNs can be enhanced via h- and p-refinement.\n",
      "No images found in doc 24.\n",
      "Page content: 4.6.1 Accuracy Test\n",
      "The impact of h-refinement is examined using an example where ω = 4 π . The process begins with a single element, after which the domain is partitioned into 4 × 4 grids, and then into 8 × 8 grids, while keeping the number of quadrature points per element constant at 80 × 80 and using five test functions in each direction within each element. The model has difficulty accurately depicting the shape or magnitude of the solution when only one element is used. However, when the grid is expanded to 8 × 8 elements, the error is significantly reduced to approximately O (10 -3 ), as illustrated in Figure 9(a). In the case of p-refinement, increasing the number of test functions in a 1 × 1 element grid from 5 × 5 to 20 × 20 reduces the error from O (10 ) to 0 O (10 -2 ), as depicted in Figure 9(b), thereby proving the effectiveness\n",
      "of p-refinement. A detailed error analysis for both h-refinement and p-refinement is provided in the Appendix B.1.\n",
      "Figure 9: Left: Effect of p-refinement(left) and h-refinement(right) on FastVPINNs.\n",
      "No images found in doc 25.\n",
      "Page content: 4.6.2 Efficiency Test: Comparison of FastVPINNs with PINNs and Hp-VPINNs\n",
      "In this section, we assess the performance of our FastVPINNs framework by comparing it with two alternative methods: PINNs and the original version of hp-VPINNs. To measure computational proficiency, we recorded the duration needed to finish one training cycle for each framework. The evaluations were performed over 1,000 cycles to determine the median duration consumed. The results of the comparision are portrayed in Figure 10(a), where the x-axis indicates the count of residual points used for the calculations (collocation points for PINN and quadrature points for hp-VPINN) in addition to the total count of elements taken into account. For both hp-VPINNs and FastVPINNs, we applied five test functions on the xand y-axes, culminating in a sum of 25 quadrature points per element and 25 test functions in total. This experimental arrangement facilitates a straightforward efficiency comparison between FastVPINNs and PINNs, using the count of collocation points (quadrature) as a shared factor. The results depicted validate that FastVPINNs surpass both PINNs and the original version of hp-VPINNs library in terms of training time, regardless of whether tf.float32 or tf.float64 precision is employed.\n",
      "In contrast to the linear rise in training time observed with the increase in elements for the original version of hp-VPINNs, FastVPINNs demonstrate a nearly steady training time up to 400 elements, as depicted in Figure 10(b)\n",
      "Section 4.8 provides additional understanding regarding the influence of different hyperparameters such as the count of test functions, quadrature points, and elements on the training duration of FastVPINNs.\n",
      "No images found in doc 26.\n",
      "Page content: 4.6.3 Performance of FastVPINNs on higher frequency problems\n",
      "Spectral bias is a phenomenon that describes the slower learning rate of neural networks for higher frequencies compared to lower frequency solutions during the training process Cao et al. (2020). The h-refinement technique can confine test functions to a more restricted area within our domain, enabling the network to detect higher frequency solutions in that\n",
      "Figure 10: (a) Variation of computational time with the number of quadrature (residual) points, plotted against the median time taken per epoch; (b) Comparison of computational time between hp-VPINNs and FastVPINNs for varying numbers of elements.\n",
      "specific area Kharazmi et al. (2021). In contrast to hp-VPINNs, which face longer training durations with an increased number of elements, the capability of FastVPINNs to sustain a consistent training time offers computational benefits for problems typified by higherfrequency solutions.\n",
      "The aim of this section is to assess and contrast the efficacy of PINNs and FastVPINNs when dealing with solutions of varying frequencies, while keeping the number of residual points constant. In the FastVPINN scenario, the h-refinement will be adjusted according to the solution's frequency. For example, for a solution frequency of ω = 2 π , a 2x2 element set-up will be used, each comprising 40x40 quadrature points. If the frequency is ω = 4 π , the setup will be modified to 4x4 elements, each with 20x20 quadrature points, and so on. FastVPINNs uses five test functions in each direction. It is important to emphasize that the total count of quadrature points will remain fixed at 6,400 for all FastVPINNs configurations, equaling the number of collocation points used for PINNs training. Both models use the same parameters: 1000 Dirichlet boundary points, a neural network with\n",
      "three hidden layers, each containing 30 neurons, trained over 100,000 iterations with a constant learning rate of 0.001 using the Adam optimizer Kingma and Ba (2014)\n",
      "Figure 11: (a) Comparing MAE for PINNs and FastVPINNs over different frequencies. (b) time taken for PINNs and FastVPINNs to reach an MAE of 5 × 10 -2 for different frequencies.\n",
      "No images found in doc 27.\n",
      "Page content: 4.6.3 Performance of FastVPINNs on higher frequency problems\n",
      "Figure 11(a) demonstrates that FastVPINNs consistently outperform PINNs in Mean Absolute Error (MAE) across all tested frequencies, emphasizing the benefits of h-refinement. Furthermore, FastVPINNs reach the MAE target threshold more rapidly than traditional PINNs, as illustrated in Figure 11(b), highlighting their superior speed and accuracy. This also underscores the importance of carefully selecting hyperparameters such as N elem , N test , and N quad for FastVPINNs to optimize convergence and achieve efficiency and accuracy surpassing conventional PINNs.\n",
      "No images found in doc 28.\n",
      "Page content: 4.6.4 FastVPINNs on Complex Geometries\n",
      "In order to assess the proficiency of the FastVPINN framework in handling intricate domains with a large number of elements, we used it in a 2D convection-diffusion problem (12)on a spur gear domain (Ω gear ) depicted in Figure 3. The gear mesh, made up of 14,192 quadrilateral cells, was created using Gmsh(Geuzaine and Remacle (2009)).\n",
      "\n",
      "where\n",
      "\n",
      "During this experiment, we used four testing functions per direction and assigned 25 quadrature points to each component. This setup resulted in a total of 354,800 quadrature points, plus an extra 6,096 points specifically for the Dirichlet boundary ( ∂ Ω gear ). The neural network was made up of 3 layers, each layer containing 50 neurons, and was launched with an initial learning rate of 0.005. This rate was adjusted through a method that reduced\n",
      "it by a factor of 0.99 for every 1,000 training iterations. The model was trained for a total of 150,000 iterations.\n",
      "Figure 12: (a) Exact Solution obtained using FEM. (b) Predicted solution-FastVPINNs (c) Pointwise absolute error.\n",
      "Figure (12) shows the exact and predicted solution along with the absolute point error. It should be noted that the model training was remarkably quick, finishing in less than 35 minutes, and each iteration took approximately 13 milliseconds. This highlights the efficiency of FastVPINNs in solving problems in domains with larger element counts and skewed elements, which are challenging for the original version of hp-VPINNs. The comparison of prediction times between FEM and FastVPINNs for varying numbers of degrees of freedom (DOFs) is discussed in Appendix B.2.\n",
      "No images found in doc 29.\n",
      "Page content: 4.7 Investigating Inverse Problems with FastVPINNs\n",
      "In PINNs, inverse problems involve the use of neural networks to infer unidentified PDE parameters, aided by observed solutions at scattered data points, usually in complex physical systems. By enhancing the loss function with data from sensor points scattered across the 2D domain, the network is capable of simultaneously ascertaining the solution to the Poisson equation and the value of the parameter ϵ . Consequently, the loss function for this issue is formulated as follows.\n",
      "\n",
      "In this context, L s denotes the loss term that arises from the discrepancy between observed solutions at sensor points and their corresponding predictions from the neural network. The terms L v and L b represent the variational loss and the boundary loss, respectively, as indicated in (11). The hyperparameters τ and γ are adjusted to suit the specific problem and the chosen architecture. This study investigates two separate categories of inverse problems related to predicting diffusion parameters: one involves uniform diffusion parameter prediction in a Poisson-2D problem, and the other involves space-dependent diffusion parameter prediction in a Convection-Diffusion-2D problem.\n",
      "No images found in doc 30.\n",
      "Page content: 4.7.1 Estimating Constant Diffusion Parameters\n",
      "In the context of uniform parameter inverse problems, we consider a two-dimensional (2D) Poisson equation as given in Eq. (13). The objective is to predict the constant diffusion parameter, denoted as ϵ , and the corresponding solution u x ( ).\n",
      "Figure 13: Schematics of VPINNs for space dependent inverse parameter modelling.\n",
      "\n",
      "Suppose the epsilon ( ) is spatially invariant, ϵ we can incorporate it as a single trainable variable within the FastVPINNs framework. To demonstrate this approach, we built a FastVPINN with a 30 × 3 neural network architecture, 50 randomly distributed sensor points, a 2 × 2 element domain discretization, and 40 × 40 quadrature points per element. The exact solution to this problem is u x, y ( ) = 10sin( x ) tanh( x e ) -ϵx 2 . The initial guess of epsilon ( ϵ initial ) is taken as 2, and the actual value of epsilon ( ϵ actual ) is 0.3. Training is carried out until it reaches the convergence criteria of | ϵ predicted -ϵ actual | < 10 -5 . The network converged in 8909 epochs with a mean absolute error of the solution at 6 6 . × 10 -2 . The total training time was close to 18 s with a mean time per epoch of 2 ms. Figure 14 presents the exact and predicted values of both the solution and ϵ .\n",
      "No images found in doc 31.\n",
      "Page content: 4.7.2 Predicting Space-Dependent Diffusion Parameters\n",
      "This section addresses the more challenging case of predicting space-dependent parameters in partial differential equations (PDEs). As illustrated in Figure 13, the architecture of the neural network is modified to output both the solution and the space-dependent diffusion parameter at each point, enabling their simultaneous prediction. The network is guided by sensor point data, which are substituted here with the exact solution to accurately determine both the solution and its corresponding diffusion parameter. In this example, we consider a two-dimensional (2D) convection-diffusion equation as shown in Equation (14), solved on a circular domain using 1024 quadrilateral elements.\n",
      "\n",
      "where\n",
      "\n",
      "Figure 14: Inverse problem on FastVPINNs with constant diffusion parameter.\n",
      "15 shows the reference FEM solution, FastVPINNs solution and the corresponding pointwise error for both solution and ϵ . We observe that the FastVPINNs framework can reasonably predict both the solution and the spatially varying diffusion parameter with errors of the order of O (10 -2 )\n",
      "No images found in doc 32.\n",
      "Page content: 4.8 Impact of Hyperparameters on FastVPINNs' Performance\n",
      "To conclude our evaluation of FastVPINNs, we investigated the impact of three critical hyperparameters on training time using a Poisson2D problem as an example. These hyperparameters are: N quad (quadrature points per element), N test (shape functions per element), and N elem (number of elements). All experiments utilized a neural network architecture consisting of 30 layers with 3 neurons each, and conducted over 1000 training iterations. The median time per epoch was used for data visualization. Figure 16(a) illustrates the relationship between N test and N quad for a fixed N elem of 1, showing that the training time per epoch remains relatively constant regardless of the number of N test functions, up to 10,000 quadrature points. Beyond this threshold, an increase in training time becomes noticeable, which depends on the parameters involved. Figure 16(b) shows the impact of varying N test and N elem with a fixed N quad of 100 per element. Here, the execution time remains stable across different N test functions until the number of elements reaches 100, beyond which it begins to increase. Figure 16(c) shows the effects of varying N quad and N elem while maintaining a constant N test of 100 per element. Figures suggest that while the overall memory occupied by the tensors might not change for certain\n",
      "Figure 15: (a) Exact solution( u ) obtained from FEM(ParMooN). (b) Predicted SolutionFastVPINNs. (c) Absolute error: FEM vs FastVPINNs solution. (d) Exact solution diffusion parameter( ϵ actual ). (e) Predicted diffusion parameter by FastVPINNs( ϵ predicted ) (f) Absolute error: ϵ actual vs ϵ predicted .\n",
      "combinations of N test and N quad , the number of quadrature points ( N quad ) has a more pronounced impact on training time compared to the number of test functions ( N test ). This observation can be attributed to the tensor-based loss computation, which performs a reduction operation along the N quad dimension, thereby underscoring the importance of N quad in influencing training time.\n",
      "No images found in doc 33.\n",
      "Page content: 5 Conclusion\n",
      "In this work, we addressed the existing challenges of hp-VPINNs, which excel in capturing high-frequency solutions but struggle with the extended training times associated with problems involving a large number of elements and complex geometries. We introduced FastVPINNs, a novel framework that employs tensor-based computations to significantly reduce training time dependence on the number of elements and to efficiently handle complex meshes. We demonstrated a 100x speedup compared to the existing hp-VPINNs implementation. Additionally, with proper hyperparameter selection, FastVPINNs can surpass state-of-the-art PINN codes in both speed and accuracy. Our method's ability to manage complex geometries with a large number of elements was showcased by solving a forward problem on a 14,000-element gear quad mesh. We successfully solved inverse problems in complex domains, as evidenced by estimating a diffusion parameter in a circular domain with 1,024 elements. This task was completed in less than 200 seconds for 100,000 epochs, which would have taken hours with the existing hp-VPINNs implementation. We also examined how hyperparameters, such as the number of test functions ( N test ), quadrature\n",
      "Figure 16: Comparative analysis of the median training time per epoch for different hyperparameters: (a) Number of test functions ( N test ) vs Number of quadrature points ( N quad) with ( N elem =1), (b) Number of Elements ( N elem ) vs Number of test functions ( N test ) with quadrature points fixed at 10x10 ( N quad =10*10), (c) Number of elements ( N elem ) vs Number of quadrature points ( N quad ) with fixed number of test functions ( N test =10*10).\n",
      "points ( N quad ), and element count ( N elem ), influence the training time. This analysis offers valuable insights for selecting the most suitable hyperparameters for specific problems. The versatility of FastVPINNs unlocks its potential for real-world applications in fields such as fluid dynamics, where complex geometries and massive datasets are prevalent. Looking ahead, we aim to expand the capabilities of FastVPINNs to include triangular elements and 3D domains, further broadening its impact in scientific and engineering fields.\n",
      "No images found in doc 34.\n",
      "Page content: Acknowledgments and Disclosure of Funding\n",
      "We thank Shell Research, India, for providing partial funding for this project. We are thankful to the MHRD Grant No. STARS-1/388 (SPADE) for partial support. We acknowledge Pratham Sunkad, for his assistance in running experiments for this paper.\n",
      "No images found in doc 35.\n",
      "Page content: References\n",
      "M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia,\n",
      "R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man' e, R. Monga, S. Moore,\n",
      "D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar,\n",
      "P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vi' egas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/ . Software available\n",
      "from tensorflow.org.\n",
      "D. W. Abueidda, Q. Lu, and S. Koric. Meshless physics-informed deep learning method for three-dimensional solid mechanics. International Journal for Numerical Methods in Engineering , 122(23):7182-7201, 2021.\n",
      "N. Baker, F. Alexander, T. Bremer, A. Hagberg, Y. Kevrekidis, H. Najm, M. Parashar, A. Patra, J. Sethian, S. Wild, K. Willcox, and S. Lee. Workshop report on basic research needs for scientific machine learning: Core technologies for artificial intelligence. 2 2019. doi: 10.2172/1478744. URL https://www.osti.gov/biblio/1478744 .\n",
      "W. Bangerth, R. Hartmann, and G. Kanschat. deal. II-a general-purpose object-oriented finite element library. ACM Transactions on Mathematical Software (TOMS) , 33(4): 24-es, 2007.\n",
      "No images found in doc 36.\n",
      "Page content: References\n",
      "S. Cai, Z. Mao, Z. Wang, M. Yin, and G. E. Karniadakis. Physics-informed neural networks (PINNs) for fluid mechanics: A review. Acta Mechanica Sinica , 37(12):1727-1738, 2021.\n",
      "Y. Cao, Z. Fang, Y. Wu, D.-X. Zhou, and Q. Gu. Towards understanding the spectral bias of deep learning, 2020.\n",
      "S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, and F. Piccialli. Scientific machine learning through physics-informed neural networks: Where we are and what's next. Journal of Scientific Computing , 92(3):88, 2022.\n",
      "H. Eivazi, M. Tahani, P. Schlatter, and R. Vinuesa. Physics-informed neural networks for solving Reynolds-averaged Navier-Stokes equations. Physics of Fluids , 34(7), 2022.\n",
      "S. Ganesan and M. Shah. SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and preconditioned iterative methods. arXiv preprint arXiv:2007.00056 , 2020.\n",
      "S. Ganesan and L. Tobiska. Finite elements: Theory and algorithms . Cambridge University Press, 2017.\n",
      "C. Geuzaine and J.-F. Remacle. Gmsh: A 3-D finite element mesh generator with builtin pre- and post-processing facilities. International Journal for Numerical Methods in Engineering , 79(11):1309-1331, 2009. doi: https://doi.org/10.1002/nme.2579. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.2579 .\n",
      "E. Haghighat, M. Raissi, A. Moure, H. Gomez, and R. Juanes. A physics-informed deep learning framework for inversion and surrogate modeling in solid mechanics. Computer Methods in Applied Mechanics and Engineering , 379:113741, 2021.\n",
      "No images found in doc 37.\n",
      "Page content: References\n",
      "E. Kharazmi. hp-VPINNs: High-performance variational physics-informed neural networks, 2023. URL https://github.com/ehsankharazmi/hp-VPINNs . Accessed: 2023-12-01.\n",
      "E. Kharazmi, Z. Zhang, and G. E. Karniadakis. Variational physics-informed neural networks for solving partial differential equations. arXiv preprint arXiv:1912.00873 , 2019.\n",
      "E. Kharazmi, Z. Zhang, and G. E. Karniadakis. hp-VPINNs: Variational physics-informed neural networks with domain decomposition. Computer Methods in Applied Mechanics and Engineering , 374:113547, 2021.\n",
      "R. Khodayi-Mehr and M. Zavlanos. Varnet: Variational neural networks for the solution of partial differential equations. In Learning for Dynamics and Control , pages 298-307. PMLR, 2020.\n",
      "D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR , abs/1412.6980, 2014. URL https://api.semanticscholar.org/CorpusID:6628106 .\n",
      "I. Lagaris, A. Likas, and D. Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. IEEE Transactions on Neural Networks , 9(5):987-1000, 1998. doi: 10.1109/72.712178.\n",
      "C. Liu and H. Wu. cv-PINN: Efficient learning of variational physics-informed neural network with domain decomposition. Extreme Mechanics Letters , 63:102051, 2023. ISSN 2352-4316. doi: https://doi.org/10.1016/j.eml.2023.102051. URL https://www. sciencedirect.com/science/article/pii/S2352431623000974 .\n",
      "L. Lu, X. Meng, Z. Mao, and G. E. Karniadakis. DeepXDE: A deep learning library for solving differential equations. SIAM review , 63(1):208-228, 2021a.\n",
      "No images found in doc 38.\n",
      "Page content: References\n",
      "L. Lu, R. Pestourie, W. Yao, Z. Wang, F. Verdugo, and S. G. Johnson. Physics-informed neural networks with hard constraints for inverse design. SIAM Journal on Scientific Computing , 43(6):B1105-B1132, 2021b.\n",
      "Z. Mao, A. D. Jagtap, and G. E. Karniadakis. Physics-informed neural networks for highspeed flows. Computer Methods in Applied Mechanics and Engineering , 360:112789, 2020.\n",
      "NVIDIA. NVIDIA Modulus Documentation. https://docs.nvidia.com/deeplearning/ modulus/modulus-sym/index.html , 2023. Accessed: 2023-03-10.\n",
      "NVIDIA Modulus. https://developer.nvidia.com/modulus . Last accessed Jan 01, 2024.\n",
      "No images found in doc 39.\n",
      "Page content: References\n",
      "A. F. Psaros, X. Meng, Z. Zou, L. Guo, and G. E. Karniadakis. Uncertainty quantification in scientific machine learning: Methods, metrics, and comparisons. Journal of Computational Physics , 477:111902, 2023.\n",
      "N. Radin, S. Klinkel, and O. Altay. Effects of variational formulations on physics-informed neural network performance in solid mechanics. PAMM , page e202300222, 2023.\n",
      "M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics , 378:686-707, 2019.\n",
      "J. D. Smith, Z. E. Ross, K. Azizzadenesheli, and J. B. Muir. HypoSVI: Hypocentre inversion with Stein variational inference and physics informed neural networks. Geophysical Journal International , 228(1):698-710, 08 2021. ISSN 0956-540X. doi: 10.1093/gji/ggab309. URL https://doi.org/10.1093/gji/ggab309 .\n",
      "U. Wilbrandt, C. Bartsch, N. Ahmed, N. Alia, F. Anker, L. Blank, A. Caiazzo, S. Ganesan, S. Giere, G. Matthies, et al. ParMooN-a modernized program package based on mapped finite elements. Computers & Mathematics with Applications , 74(1):74-88, 2017.\n",
      "M. Yang and J. T. Foster. hp-Variational Physics-Informed Neural Networks for Nonlinear Two-Phase Transport in Porous Media. Journal of Machine Learning for Modeling and Computing , 2(2), 2021.\n",
      "E. Zhang, M. Dao, G. E. Karniadakis, and S. Suresh. Analyses of internal structures and defects in materials using physics-informed neural networks. Science advances , 8(7): eabk0644, 2022.\n",
      "No images found in doc 40.\n",
      "Page content: A.1 Bilinear Transformation\n",
      "Let b 0 ( -1 , -1), b 1 (1 , -1), b 2 (1 1), , b 3 ( -1 1) be the vertices , of the reference element ˆ , K see Figure 4. For any function u X ( ), we denote u X ( ) = u F ( k ( ˆ )) X = ˆ( ˆ ). u X Further, the derivatives of the function, ∂u/∂x and ∂u/∂y on the original element can be obtained in terms of the derivatives defined on the refernce element ∂u/∂ξ ˆ and ∂u/∂η ˆ as follows:\n",
      "\n",
      "\n",
      "\n",
      "we can express this relation as,\n",
      "\n",
      "where,\n",
      "\n",
      "Finally, we have Finally, we have\n",
      "\n",
      "where, D is the determinant of the Jacobian matrix\n",
      "No images found in doc 41.\n",
      "Page content: A.2 Algorithm : Premultiplier Assembly for Algorithm 2\n",
      "Algorithm : hp-VPINNs vectorised code - Premultiplier Assembly\n",
      "# Compute the prematrix multipliers for shapefunctions and gradients # Shape: (N_test , N_quad) for j in range(N_test): for q in range(N_quad): ' V_k[j][q] = quad_wt[q] * v_k[j][q] # Premult. shape mat V_x[j][q] = quad_wt[q] * v_kx[j][q] # Premult. grad x mat V_y[j][q] = quad_wt[q] * v_ky[j][q] # Premult. grad y mat # Compute Forcing Matrix # Shape (N_Elem , N_Test) for n in range(N_elem): for j in range(N_test): for q in range(N_quad): # xi and eta are quadrature co-ordinates in reference domain x,y = fe.get_actual_coordinates(n,xi[q],eta[q]) F[n][j] += j[n][q] * qw[q] * force_fn(x,y) * test[j][q] # Collect the jacobian terms and stack them # Shape: (N_quad , N_elem) for q in range(N_quad): for n in range(N_elem): J_x[q][n] = j[n][q] / j_x[n][q] # Jacobian x matrix J_y[q][n] = j[n][q] / j_y[n][q] # Jacobian y matrix\n",
      "No images found in doc 42.\n",
      "Page content: B.1 Effect of h- and p-refinement in FastVPINNs\n",
      "Figure 17: Effect of h-refinement on the accuracy of solving the two-dimensional Poisson equation. The first, second, and third columns are the domain decomposition, FastVPINNs solution, and pointwise test error, respectively. From top to bottom: N elem = 1, N elem = 16 and N elem = 64. For each element, we use 80 × 80 quadrature points and 5 test functions in each direction.\n",
      "Figure 18: Effect of p-refinement on the accuracy of solution of two-dimensional Poisson's equation on 1 element. The first and second columns are the FastVPINNs solution and point-wise test error, respectively. From top to bottom: N test = 5 × 5, N test = 10 × 10, N test = 15 × 15 and N test = 20 × 20. The element has 80 × 80 total quadrature points.\n",
      "Table 1: Time Taken (in s) for Prediction using FEM and PINNs\n",
      "No images found in doc 43.\n",
      "Page content: B.1 Effect of h- and p-refinement in FastVPINNs\n",
      "Table 1: Time Taken (in s) for Prediction using FEM and PINNs\n",
      "29302, FEM = 2.638. 29302, PINNs = 7.807e-4. 115868, FEM = 13.0352. 115868, PINNs = 7.978e-4. 259698, FEM = 32.220. 259698, PINNs = 1.777e-3. 460792, FEM = 50.680. 460792, PINNs = 3.139e-3. 719150, FEM = 81.784. 719150, PINNs = 4.890e-3. 1034772, FEM = 172.967. 1034772, PINNs = 7.023e-3\n",
      "No images found in doc 44.\n",
      "Page content: B.2 Time Comparison - FastVPINNs vs FEM\n",
      "The Table 1 and Figure 19 below represents the time required for the prediction of the solution using PINNs and FEM. It's important to note that for FastVPINNs, this time does not include the training time.\n",
      "Figure 19: Comparision of time taken for prediction by FEM and PINNs for varying number of quadrature points.\n",
      "No images found in doc 45.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the document to extract images\n",
    "for doc_idx, doc in enumerate(docs):\n",
    "    print(f\"Page content: {doc.page_content}\")\n",
    "    \n",
    "    # Check if images exist in the document\n",
    "    if hasattr(doc, 'images'):\n",
    "        print(f\"Found images in doc {doc_idx}: {len(doc.images)} images found.\")\n",
    "        \n",
    "        for img_idx, img in enumerate(doc.images):\n",
    "            print(f\"Image {img_idx}: {type(img)}\")\n",
    "            try:\n",
    "                # Handle the image depending on its type\n",
    "                if isinstance(img, bytes):  # Byte data\n",
    "                    img_data = io.BytesIO(img)  # Convert byte data to a file-like object\n",
    "                    image = Image.open(img_data)  # Open image using Pillow\n",
    "                else:\n",
    "                    # If it's a file path, directly open the image (if possible)\n",
    "                    image = Image.open(img)\n",
    "                \n",
    "                # Save the image\n",
    "                image_path = os.path.join(output_dir, f\"extracted_image_{doc_idx}_{img_idx}.png\")\n",
    "                image.save(image_path)\n",
    "                print(f\"Extracted image saved at: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting image: {e}\")\n",
    "    else:\n",
    "        print(f\"No images found in doc {doc_idx}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted image saved at extracted_images/image_6_0.png\n",
      "Extracted image saved at extracted_images/image_7_0.png\n",
      "Extracted image saved at extracted_images/image_7_1.png\n",
      "Extracted image saved at extracted_images/image_8_0.png\n",
      "Extracted image saved at extracted_images/image_10_0.png\n",
      "Extracted image saved at extracted_images/image_11_0.png\n",
      "Extracted image saved at extracted_images/image_13_0.png\n",
      "Extracted image saved at extracted_images/image_14_0.png\n",
      "Extracted image saved at extracted_images/image_15_0.png\n",
      "Extracted image saved at extracted_images/image_16_0.png\n",
      "Extracted image saved at extracted_images/image_17_0.png\n",
      "Extracted image saved at extracted_images/image_18_0.png\n",
      "Extracted image saved at extracted_images/image_19_0.png\n",
      "Extracted image saved at extracted_images/image_20_0.png\n",
      "Extracted image saved at extracted_images/image_21_0.png\n",
      "Extracted image saved at extracted_images/image_22_0.png\n",
      "Extracted image saved at extracted_images/image_28_0.png\n",
      "Extracted image saved at extracted_images/image_29_0.png\n",
      "Extracted image saved at extracted_images/image_30_0.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = 'paper.pdf'\n",
    "\n",
    "# Folder where images will be saved\n",
    "output_dir = 'extracted_images'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Loop through each page\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc.load_page(page_num)\n",
    "    image_list = page.get_images(full=True)\n",
    "    \n",
    "    for img_index, img in enumerate(image_list):\n",
    "        xref = img[0]\n",
    "        image = doc.extract_image(xref)\n",
    "        image_bytes = image[\"image\"]\n",
    "        \n",
    "        # Define the path where the image will be saved\n",
    "        image_filename = os.path.join(output_dir, f\"image_{page_num}_{img_index}.png\")\n",
    "        \n",
    "        # Save the image to the specified folder\n",
    "        with open(image_filename, \"wb\") as img_file:\n",
    "            img_file.write(image_bytes)\n",
    "        print(f\"check {image_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
