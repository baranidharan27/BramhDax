{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/ibm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_docling.loader import ExportType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_env_from_colab_or_os(key):\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        try:\n",
    "            return userdata.get(key)\n",
    "        except userdata.SecretNotFoundError:\n",
    "            pass\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return os.getenv(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
    "FILE_PATH = [\"paper.pdf\"]  # Docling Technical Report\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "QUESTION = \"Which are the main AI models in Docling?\"\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
    ")\n",
    "TOP_K = 3\n",
    "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "from docling.chunking import HybridChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/ibm/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Could not load the custom kernel for multi-scale deformable attention: Error building extension 'MultiScaleDeformableAttention': [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -I/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/TH -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
      "\u001b[31mFAILED: \u001b[0mms_deform_attn_cuda.cuda.o \n",
      "/usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -I/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/TH -isystem /home/himanshu/ibm/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu:19:9: warning: #pragma once in main file\n",
      "   19 | #pragma once\n",
      "      |         ^~~~\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu:19:9: warning: #pragma once in main file\n",
      "   19 | #pragma once\n",
      "      |         ^~~~\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(69): error: no suitable conversion function from \"const at::DeprecatedTypeProperties\" to \"c10::ScalarType\" exists\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): error: no suitable conversion function from \"const at::DeprecatedTypeProperties\" to \"c10::ScalarType\" exists\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(261): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(69): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(762): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(872): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(331): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(436): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(544): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh(649): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=c10::impl::ScalarTypeToCPPTypeT<c10::ScalarType::Double>]\" \n",
      "/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu(140): here\n",
      "\n",
      "2 errors detected in the compilation of \"/home/himanshu/ibm/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu\".\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/himanshu/.cache/torch_extensions/py310_cu126/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/himanshu/.cache/torch_extensions/py310_cu126/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/himanshu/.cache/torch_extensions/py310_cu126/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/himanshu/.cache/torch_extensions/py310_cu126/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/himanshu/.cache/torch_extensions/py310_cu126/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    splits = docs\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ],\n",
    "    )\n",
    "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='FastVPINNs: Tensor-Driven Acceleration of VPINNs for Complex Geometries\\nThivin Anandh 1\\nthivinanandh@iisc.ac.in\\nDivij Ghose 1\\ndivijghose@iisc.ac.in\\nHimanshu Jain 2\\nms19026@iisermohali.ac.in\\nSashikumaar Ganesan 1 ∗\\nsashi@iisc.ac.in\\n1 Department of Computational and Data Sciences\\nIndian Institute of Science, Bangalore\\nKarnataka, India\\n2 Department of Physical Sciences\\nIndian Institute of Science Education and Research, Mohali\\nPunjab, India\\n∗ Corresponding author'\n",
      "- d.page_content=\"Abstract\\nVariational Physics-Informed Neural Networks (VPINNs) utilize a variational loss function to solve partial differential equations, mirroring Finite Element Analysis techniques. Traditional hp-VPINNs, while effective for high-frequency problems, are computationally intensive and scale poorly with increasing element counts, limiting their use in complex geometries. This work introduces FastVPINNs, a tensor-based advancement that significantly reduces computational overhead and improves scalability. Using optimized tensor operations, FastVPINNs achieve a 100-fold reduction in the median training time per epoch compared to traditional hp-VPINNs. With proper choice of hyperparameters, FastVPINNs surpass conventional PINNs in both speed and accuracy, especially in problems with highfrequency solutions. Demonstrated effectiveness in solving inverse problems on complex domains underscores FastVPINNs' potential for widespread application in scientific and engineering challenges, opening new avenues for practical implementations in scientific machine learning.\\nKeywords: Physics-informed neural networks, Variational physics-informed neural networks, Domain decomposition, hp-Variational physics-informed neural networks\"\n",
      "- d.page_content='1 Introduction\\nAt present, the realm of applied mathematics is witnessing substantial progress as a result of incorporating deep learning approaches in solving partial differential equations (PDEs). These methods, collectively termed scientific machine learning (SciML) (Cuomo et al. (2022); Baker et al. (2019); Psaros et al. (2023)), often complement or replace traditional solvers. Despite the dominance of conventional numerical methods such as the finite element method (FEM), which boasts several open-source solvers (Wilbrandt et al. (2017); Bangerth et al. (2007); Ganesan and Shah (2020)), SciML has rapidly evolved. This evolution has led to a growing repertoire of accessible SciML libraries (Lu et al. (2021a); NVIDIA Modulus).\\nSince the advent of physics-informed neural networks (PINNs) (Lagaris et al. (1998); Raissi et al. (2019)), the application of such methods has surged. PINNs enhance the\\ntypical data-driven loss function of neural networks by incorporating an additional term that minimizes the residual of the underlying PDE and enforces physics-based constraints. Features such as the ease of obtaining gradients through automatic differentiation, and the ability to train networks for both forward and inverse modeling, make PINNs superior to traditional methods (Abueidda et al. (2021); Lu et al. (2021b)). Consequently, PINNs have found widespread application in various fields, including solid mechanics (Haghighat et al. (2021); Zhang et al. (2022)), fluid mechanics (Mao et al. (2020); Cai et al. (2021); Eivazi et al. (2022)), and geophysics (Smith et al. (2021)).\\nAn extension of PINNs, Variational PINNs (VPINNs), utilize the weak form of the PDE in their loss functions, mirroring the Petrov-Galerkin framework used in conventional FEM (Kharazmi et al. (2019); Khodayi-Mehr and Zavlanos (2020)). Despite their computational demand due to the necessity to numerically compute integrals in the loss function, VPINNs represent a significant step forward in applying neural networks to PDEs.'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
    "\n",
    "\n",
    "milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"docling_demo\",\n",
    "    connection_args={\"uri\": milvus_uri},\n",
    "    index_params={\"index_type\": \"FLAT\"},\n",
    "    drop_old=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=GEN_MODEL_ID,\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    task = \"text-generation\",\n",
    ")\n",
    "\n",
    "\n",
    "def clip_text(text, threshold=100):\n",
    "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/ibm/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "From the provided context, the main AI models in the field of applied mathematics and scientific machine learning (SciML) are:\n",
      "1. **Physics-Informed Neural Networks (PINNs)**: Introduced by Lagaris et...\n",
      "\n",
      "Source 1:\n",
      "  text: \"1 Introduction\\nAt present, the realm of applied mathematics is witnessing substantial progress as a result of incorporating deep learning approaches in solving partial differential equations (PDEs). These methods, collectively termed scientific machine learning (SciML) (Cuomo et al. (2022); Baker et al. (2019); Psaros et al. (2023)), often compleme...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/21', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 90.0, 't': 220.05799865722656, 'r': 522.0059814453125, 'b': 115.68000030517578, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 724]}]}, {'self_ref': '#/texts/22', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 90.0, 't': 110.13800048828125, 'r': 521.9970092773438, 'b': 87.05500030517578, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 169]}]}, {'self_ref': '#/texts/26', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 90.0, 't': 697.6300048828125, 'r': 522.0050048828125, 'b': 593.2520141601562, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 686]}]}, {'self_ref': '#/texts/27', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 90.0, 't': 588.833984375, 'r': 522.0050048828125, 'b': 525.10400390625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 425]}]}], 'headings': ['1 Introduction'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n",
      "  source: paper.pdf\n",
      "\n",
      "Source 2:\n",
      "  text: \"References\\nM. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia,\\nR. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man' e, R. Monga, S. Moore,\\nD. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar,\\nP. ...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/242', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 90.0, 't': 474.1610107421875, 'r': 522.0, 'b': 451.0780029296875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 172]}]}, {'self_ref': '#/texts/243', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 100.90899658203125, 't': 447.06201171875, 'r': 522.0059814453125, 'b': 437.52801513671875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 81]}]}, {'self_ref': '#/texts/244', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 100.90899658203125, 't': 433.51300048828125, 'r': 521.9970092773438, 'b': 423.97900390625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 80]}]}, {'self_ref': '#/texts/245', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 100.90899658203125, 't': 419.9639892578125, 'r': 522.0059814453125, 'b': 382.9930114746094, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 246]}]}, {'self_ref': '#/texts/246', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 100.90899658203125, 't': 379.3160095214844, 'r': 196.20799255371094, 'b': 369.7820129394531, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 20]}]}, {'self_ref': '#/texts/247', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 90.0, 't': 357.0350036621094, 'r': 521.9990234375, 'b': 320.40301513671875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 208]}]}, {'self_ref': '#/texts/248', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 90.0, 't': 307.656005859375, 'r': 522.0040283203125, 'b': 257.135009765625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 330]}]}, {'self_ref': '#/texts/249', 'parent': {'$ref': '#/groups/6'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 24, 'bbox': {'l': 90.0, 't': 244.7270050048828, 'r': 522.0029907226562, 'b': 208.09500122070312, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 180]}]}], 'headings': ['References'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n",
      "  source: paper.pdf\n",
      "\n",
      "Source 3:\n",
      "  text: \"References\\nE. Kharazmi. hp-VPINNs: High-performance variational physics-informed neural networks, 2023. URL https://github.com/ehsankharazmi/hp-VPINNs . Accessed: 2023-12-01.\\nE. Kharazmi, Z. Zhang, and G. E. Karniadakis. Variational physics-informed neural networks for solving partial differential equations. arXiv preprint arXiv:1912.00873 , 2019.\\n...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/260', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 477.92498779296875, 'r': 522.0029907226562, 'b': 454.50299072265625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 163]}]}, {'self_ref': '#/texts/261', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 442.114013671875, 'r': 522.0050048828125, 'b': 419.031005859375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 174]}]}, {'self_ref': '#/texts/262', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 406.3030090332031, 'r': 522.0059814453125, 'b': 369.6700134277344, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 202]}]}, {'self_ref': '#/texts/263', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 356.9419860839844, 'r': 521.9979858398438, 'b': 320.3089904785156, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 186]}]}, {'self_ref': '#/texts/264', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 307.58099365234375, 'r': 522.0009765625, 'b': 284.15899658203125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 150]}]}, {'self_ref': '#/texts/265', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 271.7699890136719, 'r': 522.0050048828125, 'b': 235.13699340820312, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 206]}]}, {'self_ref': '#/texts/266', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 222.40899658203125, 'r': 522.0, 'b': 171.88800048828125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 303]}]}, {'self_ref': '#/texts/267', 'parent': {'$ref': '#/groups/7'}, 'children': [], 'content_layer': 'body', 'label': 'list_item', 'prov': [{'page_no': 25, 'bbox': {'l': 90.0, 't': 159.49899291992188, 'r': 522.0059814453125, 'b': 136.41600036621094, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 151]}]}], 'headings': ['References'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6727184973767895406, 'filename': 'paper.pdf'}}\n",
      "  source: paper.pdf\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
    "\n",
    "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
    "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
    "for i, doc in enumerate(resp_dict[\"context\"]):\n",
    "    print()\n",
    "    print(f\"Source {i+1}:\")\n",
    "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
    "    for key in doc.metadata:\n",
    "        if key != \"pk\":\n",
    "            val = doc.metadata.get(key)\n",
    "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
    "            print(f\"  {key}: {clipped_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
